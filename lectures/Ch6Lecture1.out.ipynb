{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ch6 Lecture 1\n",
        "\n",
        "# *Review*\n",
        "\n",
        "# *Chapter 1: Linear Systems*\n",
        "\n",
        "## *Linear Systems*\n",
        "\n",
        "ch1Lecture1b, ch1Lecture2\n",
        "\n",
        "-   Applications of linear systems\n",
        "-   Putting linear systems in matrix form\n",
        "-   \\*Gauss-Jordan to get to row echelon form\n",
        "-   \\*Solving linear systems with augmented matrices\n",
        "-   Free vs bound variables\n",
        "-   Ill-conditioned systems & rounding errors\n",
        "\n",
        "## \n",
        "\n",
        "Getting to row echelon form: $$\n",
        "\\left[\\begin{array}{rrr}\n",
        "1 & 1 & 5 \\\\\n",
        "0 & -3 & -9\n",
        "\\end{array}\\right] \\overrightarrow{E_{2}(-1 / 3)}\\left[\\begin{array}{lll}\n",
        "1 & 1 & 5 \\\\\n",
        "0 & 1 & 3\n",
        "\\end{array}\\right] \\overrightarrow{E_{12}(-1)}\\left[\\begin{array}{lll}\n",
        "1 & 0 & 2 \\\\\n",
        "0 & 1 & 3\n",
        "\\end{array}\\right] .\n",
        "$$\n",
        "\n",
        "## *Augmented matrix to solve linear system:*\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "z & =2 \\\\\n",
        "x+y+z & =2 \\\\\n",
        "2 x+2 y+4 z & =8\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        ". . .\n",
        "\n",
        "Augmented matrix:\n",
        "\n",
        "$$\n",
        "\\left[\\begin{array}{llll}\n",
        "0 & 0 & 1 & 2 \\\\\n",
        "1 & 1 & 1 & 2 \\\\\n",
        "2 & 2 & 4 & 8\n",
        "\\end{array}\\right] \\stackrel{E_{12}}{\\longrightarrow}\\left[\\begin{array}{llll}\n",
        "(1 & 1 & 1 & 2 \\\\\n",
        "0 & 0 & 1 & 2 \\\\\n",
        "2 & 2 & 4 & 8\n",
        "\\end{array}\\right] \\xrightarrow[E_{31}(-2)]{\\longrightarrow}\\left[\\begin{array}{rlll}\n",
        "1 & 1 & 1 & 2 \\\\\n",
        "0 & 0 & 2 & 4 \\\\\n",
        "0 & 0 & 1 & 2\n",
        "\\end{array}\\right]\n",
        "$$\n",
        "\n",
        "## \n",
        "\n",
        "## \n",
        "\n",
        "We keep on going… $$\n",
        "\\begin{aligned}\n",
        "& {\\left[\\begin{array}{rrrr}\n",
        "(1) & 1 & 1 & 2 \\\\\n",
        "0 & 0 & 2 & 4 \\\\\n",
        "0 & 0 & 1 & 2\n",
        "\\end{array}\\right] \\xrightarrow[E_{2}(1 / 2)]{\\longrightarrow}\\left[\\begin{array}{rrrr}\n",
        "1 & 1 & 1 & 2 \\\\\n",
        "0 & 0 & 1 & 2 \\\\\n",
        "0 & 0 & 1 & 2\n",
        "\\end{array}\\right]} \\\\\n",
        "& \\overrightarrow{E_{32}(-1)}\\left[\\begin{array}{rrrr}\n",
        "(1) & 1 & 1 & 2 \\\\\n",
        "0 & 0 & 1 & 2 \\\\\n",
        "0 & 0 & 0 & 0\n",
        "\\end{array}\\right] \\xrightarrow[E_{12}(-1)]{\\longrightarrow}\\left[\\begin{array}{rrrr}\n",
        "(1) & 1 & 0 & 0 \\\\\n",
        "0 & 0 & 1 & 2 \\\\\n",
        "0 & 0 & 0 & 0\n",
        "\\end{array}\\right] .\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "There’s still no information on $y$.\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "& x=-y \\\\\n",
        "& z=2 \\\\\n",
        "& y \\text { is free. }\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "# *Chapter 2: Matrices*\n",
        "\n",
        "## *Matrix multiplication*\n",
        "\n",
        "ch2Lecture1\n",
        "\n",
        "-   Matrix-vector multiplication as a linear combination of columns\n",
        "-   Matrix multiplication as an operation\n",
        "-   \\*Scaling, rotation, shear\n",
        "\n",
        "### *Scaling and rotation*\n",
        "\n",
        "To rotate a vector by $\\theta$:\n",
        "\n",
        "$$\n",
        " =\\left[\\begin{array}{rr}\n",
        "\\cos \\theta &-\\sin \\theta \\\\\n",
        "\\sin \\theta & \\cos \\theta\n",
        "\\end{array}\\right]\\left[\\begin{array}{l}\n",
        "r \\cos \\phi \\\\\n",
        "r \\sin \\phi\n",
        "\\end{array}\\right]=\\left[\\begin{array}{rr}\n",
        "\\cos \\theta&-\\sin \\theta \\\\\n",
        "\\sin \\theta & \\cos \\theta\n",
        "\\end{array}\\right]\\left[\\begin{array}{l}\n",
        "x \\\\\n",
        "y\n",
        "\\end{array}\\right]\n",
        "$$\n",
        "\n",
        ". . .\n",
        "\n",
        "Scaling:\n",
        "\n",
        "$$ A = \\left[\\begin{array}{ll} z_1 & 0 \\\\ 0 & z_2 \\end{array}\\right] $$\n",
        "\n",
        "Shearing: adding a constant shear factor times one coordinate to another\n",
        "coordinate of the point. $$\n",
        "A = \\left[\\begin{array}{ll} 1 & s_2 \\\\ s_1 & 1 \\end{array}\\right]\n",
        "$$\n",
        "\n",
        "## *Graphs and Directed Graphs*\n",
        "\n",
        "ch2Lecture2\n",
        "\n",
        "-   \\*Adjacency and incidence matrices\n",
        "-   Degree of a vertex\n",
        "-   \\*Paths and cycles\n",
        "-   PageRank\n",
        "\n",
        "### *Adjacency and incidence matrices*\n",
        "\n",
        "**Adjacency matrix**: A square matrix whose $(i, j)$ th entry is the\n",
        "number of edges going from vertex $i$ to vertex $j$\n",
        "\n",
        "**Incidence matrix**: A matrix whose rows correspond to vertices and\n",
        "columns correspond to edges. The $(i, j)$ th entry is 1 if vertex $i$ is\n",
        "the tail of edge $j$, -1 if it is the head, and 0 otherwise.\n",
        "\n",
        "### *Paths and cycles*\n",
        "\n",
        "-   Number of paths of length $n$ from vertex $i$ to vertex $j$ is the\n",
        "    $(i, j)$ th entry of the matrix $A^{n}$.\n",
        "-   Vertex power is the sum of the entries in the $ith$ row of\n",
        "    $A+A^{2}$.\n",
        "-   In an the incidence matrix of a digraph which is a cycle, every row\n",
        "    must sum to zero.\n",
        "\n",
        "## *Discrete Dynamical Systems*\n",
        "\n",
        "Ch2Lecture2\n",
        "\n",
        "-   Transition matrices\n",
        "-   \\*Markov chains\n",
        "\n",
        "### *Markov Chains*\n",
        "\n",
        "A **distribution vector** is a vector whose entries are nonnegative and\n",
        "sum to 1.\n",
        "\n",
        "A **stochastic matrix** is a square matrix whose columns are\n",
        "distribution vectors.\n",
        "\n",
        "A **Markov chain** is a discrete dynamical system whose initial state\n",
        "$\\mathbf{x}^{(0)}$ is a distribution vector and whose transition matrix\n",
        "$A$ is stochastic, i.e., each column of $A$ is a distribution vector.\n",
        "\n",
        "## *Difference Equations*\n",
        "\n",
        "Ch2Lecture3\n",
        "\n",
        "-   \\*Difference equations in matrix form\n",
        "-   \\*Examples\n",
        "\n",
        "### *Difference Equation in Matrix Form*\n",
        "\n",
        "From HW2: put ths difference equation in matrix form:\n",
        "\n",
        "$$\n",
        "y_{k+2}-y_{k+1}-y_{k}=0\n",
        "$$\n",
        "\n",
        ". . .\n",
        "\n",
        "Steps: 1. Make two equations. Solve for $y_{k+2}$:\n",
        "$y_{k+2}=y_{k+1}+y_{k}$. Also of course $y_{k+1}=y_{k+1}$. 2. Define the\n",
        "vector\n",
        "$\\mathbf{y}^{(k)}=\\left[\\begin{array}{l} y_{k} \\\\ y_{k+1} \\end{array}\\right]$\n",
        "3. Put the two equations in matrix form: . . .\n",
        "\n",
        "$\\left[\\begin{array}{l}y_{k+1} \\\\ y_{k+2}\\end{array}\\right]=\\left[\\begin{array}{ll}0 & 1 \\\\ 1 & 1\\end{array}\\right]\\left[\\begin{array}{c}y_{k} \\\\ y_{k+1}\\end{array}\\right]$\n",
        "\n",
        "### *Examples of difference equations*\n",
        "\n",
        "Reaction-diffusion:\n",
        "\n",
        "$$\n",
        "a_{x,t+1} = a_{x,t} + dt\\left(  \\frac{D_{a}}{dx^{2}}(a_{x+1,t} + a_{x-1,t} - 2a_{x,t})  \\right)\n",
        "$$\n",
        "\n",
        "Heat in a rod: $$\n",
        "\\begin{equation*}\n",
        "-y_{i-1}+2 y_{i}-y_{i+1}=\\frac{h^{2}}{K} f\\left(x_{i}\\right) \n",
        "\\end{equation*}\n",
        "$$\n",
        "\n",
        "## *MCMC*\n",
        "\n",
        "-   MCMC (Ch2 lecture 4)\n",
        "    -   Simulate a distribution using a Markov chain\n",
        "    -   Sample from the simulated distribution\n",
        "-   Restricted Boltzmann Machines (Ch2 lecture 4)\n",
        "\n",
        "## *Inverses and determinants*\n",
        "\n",
        "(Ch2 lecture 5)\n",
        "\n",
        "-   Inverse of a matrix\n",
        "-   \\*Determinants\n",
        "-   Singularity\n",
        "-   LU factorization (Ch2 lecture 4)\n",
        "\n",
        "### *Determinants*\n",
        "\n",
        "The **determinant** of a square $n \\times n$ matrix\n",
        "$A=\\left[a_{i j}\\right]$, $\\operatorname{det} A$, is defined\n",
        "recursively:\n",
        "\n",
        "If $n=1$ then $\\operatorname{det} A=a_{11}$;\n",
        "\n",
        "otherwise,\n",
        "\n",
        "-   suppose we have determinents for all square matrices of size less\n",
        "    than $n$\n",
        "-   Define $M_{i j}(A)$ as the determinant of the $(n-1) \\times(n-1)$\n",
        "    matrix obtained from $A$ by deleting the $i$ th row and $j$ th\n",
        "    column of $A$\n",
        "\n",
        "then\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\operatorname{det} A & =\\sum_{k=1}^{n} a_{k 1}(-1)^{k+1} M_{k 1}(A) \\\\\n",
        "& =a_{11} M_{11}(A)-a_{21} M_{21}(A)+\\cdots+(-1)^{n+1} a_{n 1} M_{n 1}(A)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "### *Laws of Determinants*\n",
        "\n",
        "-   D1: If $A$ is an upper triangular matrix, then the determinant of\n",
        "    $A$ is the product of all the diagonal elements of $A$.\n",
        "-   D2: If $B$ is obtained from $A$ by multiplying one row of $A$ by the\n",
        "    scalar $c$, then\n",
        "    $\\operatorname{det} B=c \\cdot \\operatorname{det} A$.\n",
        "-   D3: If $B$ is obtained from $A$ by interchanging two rows of $A$,\n",
        "    then $\\operatorname{det} B=$ $-\\operatorname{det} A$.\n",
        "-   D4: If $B$ is obtained from $A$ by adding a multiple of one row of\n",
        "    $A$ to another row of $A$, then\n",
        "    $\\operatorname{det} B=\\operatorname{det} A$.\n",
        "-   D5: The matrix $A$ is invertible if and only if\n",
        "    $\\operatorname{det} A \\neq 0$.\n",
        "-   D6: Given matrices $A, B$ of the same size,\n",
        "    $\\operatorname{det} A B=\\operatorname{det} A \\operatorname{det} B \\text {. }$\n",
        "-   D7: For all square matrices $A$,\n",
        "    $\\operatorname{det} A^{T}=\\operatorname{det} A$\n",
        "\n",
        "# *Chapter 3: Vector Spaces*\n",
        "\n",
        "## *Spaces of matrices*\n",
        "\n",
        "(ch3 lecture 1)\n",
        "\n",
        "-   Basis\n",
        "-   Fundamental subspaces:\n",
        "    -   Column space\n",
        "    -   Null space\n",
        "    -   Row space\n",
        "-   Rank\n",
        "-   Consistency\n",
        "\n",
        "### *Column and Row Spaces*\n",
        "\n",
        "The **column space** of the $m \\times n$ matrix $A$ is the subspace\n",
        "$\\mathcal{C}(A)$ of $\\mathbb{R}^{m}$ spanned by the columns of $A$.\n",
        "\n",
        "The **row space** of the $m \\times n$ matrix $A$ is the subspace\n",
        "$\\mathcal{R}(A)$ of $\\mathbb{R}^{n}$ spanned by the transposes of the\n",
        "rows of $A$\n",
        "\n",
        ". . .\n",
        "\n",
        "A basis for the column space of $A$ is the set of pivot columns of $A$.\n",
        "(Find these by row reducing $A$ and choosing the columns with leading\n",
        "1s)\n",
        "\n",
        "### *Null Space*\n",
        "\n",
        "The **null space** of the $m \\times n$ matrix $A$ is the subset\n",
        "$\\mathcal{N}(A)$ of $\\mathbb{R}^{n}$\n",
        "\n",
        "$$\n",
        "\\mathcal{N}(A)=\\left\\{\\mathbf{x} \\in \\mathbb{R}^{n} \\mid A \\mathbf{x}=\\mathbf{0}\\right\\}\n",
        "$$\n",
        "\n",
        ". . .\n",
        "\n",
        "$\\mathcal{N}(A)$ is just the solution set to $A \\mathbf{x}=\\mathbf{0}$\n",
        "\n",
        ". . .\n",
        "\n",
        "For example, if $A$ is invertible, $A \\mathbf{x}=\\mathbf{0}$ has only\n",
        "the trivial solution $\\mathbf{x}=\\mathbf{0}$\n",
        "\n",
        ". . .\n",
        "\n",
        "so $\\mathcal{N}(A)$ is just $\\left\\{\\mathbf{0}\\right\\}$.\n",
        "\n",
        ". . .\n",
        "\n",
        "$A$ is invertible exactly if $\\mathcal{N}(A)=\\{\\mathbf{0}\\}$\n",
        "\n",
        "### *Finding a basis for the null space*\n",
        "\n",
        "Given an $m \\times n$ matrix $A$.\n",
        "\n",
        "1.  Compute the reduced row echelon form $R$ of $A$.\n",
        "\n",
        "2.  Use $R$ to find the general solution to the homogeneous system\n",
        "    $A \\mathbf{x}=0$.\n",
        "\n",
        ". . .\n",
        "\n",
        "1.  Write the general solution\n",
        "    $\\mathbf{x}=\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)$ to the\n",
        "    homogeneous system in the form\n",
        "\n",
        ". . .\n",
        "\n",
        "$$\n",
        "\\mathbf{x}=x_{i_{1}} \\mathbf{w}_{1}+x_{i_{2}} \\mathbf{w}_{2}+\\cdots+x_{i_{n-r}} \\mathbf{w}_{n-r}\n",
        "$$\n",
        "\n",
        "where $x_{i_{1}}, x_{i_{2}}, \\ldots, x_{i_{n-r}}$ are the free\n",
        "variables.\n",
        "\n",
        ". . .\n",
        "\n",
        "1.  List the vectors\n",
        "    $\\mathbf{w}_{1}, \\mathbf{w}_{2}, \\ldots, \\mathbf{w}_{n-r}$. These\n",
        "    form a basis of $\\mathcal{N}(A)$.\n",
        "\n",
        "### *Using the Null Space*\n",
        "\n",
        "-   The general solution to $A \\mathbf{x}=\\mathbf{b}$ is\n",
        "    $\\mathbf{x}=\\mathbf{x}_{p}+\\mathbf{x}_{h}$ where $\\mathbf{x}_{p}$ is\n",
        "    a particular solution and $\\mathbf{x}_{h}$ is in the null space of\n",
        "    $A$.\n",
        "-   The null space of $A$ is orthogonal to the row space of $A$ (or the\n",
        "    column space of $A^{T}$. The dot product of any vector in the null\n",
        "    space of $A$ with any vector in the row space of $A$ is 0.)\n",
        "\n",
        "# *Chapter 4: Geometrical Aspects of Standard Spaces*\n",
        "\n",
        "## *Orthogonality*\n",
        "\n",
        "-   Geometrical intuitions (ch4 lecture 1)\n",
        "-   \\*Least Squares & Normal equations (ch4 lecture 2)\n",
        "-   Finding orthogonal bases (Gram-Schmidt) (ch4 lecture 2)\n",
        "\n",
        "### *Least Squares and Normal Equations*\n",
        "\n",
        "To find the least squares solution to $A \\mathbf{x}=\\mathbf{b}$, we\n",
        "minimize the squared error $\\left\\|A \\mathbf{x}-\\mathbf{b}\\right\\|^{2}$\n",
        "by solving the Normal Equations for $\\mathbf{x}$: $$\n",
        "\\begin{aligned}\n",
        "\\mathbf{A}^{T} \\mathbf{A} \\mathbf{x} &=\\mathbf{A}^{T} \\mathbf{b} \n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "## *Factorizations*\n",
        "\n",
        "-   \\*QR Factorization (Ch4 lecture 2)\n",
        "-   \\*Singular Value Decomposition (Ch5 lecture 2)\n",
        "\n",
        "### *QR Factorization*\n",
        "\n",
        "If $A$ is an $m \\times n$ full-column-rank matrix, then $A=Q R$, where\n",
        "the columns of the $m \\times n$ matrix $Q$ are orthonormal vectors and\n",
        "the $n \\times n$ matrix $R$ is upper triangular with nonzero diagonal\n",
        "entries.\n",
        "\n",
        "1.  Start with the columns of A,\n",
        "    $A=\\left[\\mathbf{w}_{1}, \\mathbf{w}_{2}, \\mathbf{w}_{3}\\right]$.\n",
        "    (For now assume they are linearly independent.)\n",
        "2.  Do Gram-Schmidt on the columns of $A$ to get orthonormal vectors\n",
        "    $\\mathbf{q}_{1}, \\mathbf{q}_{2}, \\mathbf{q}_{3}$.\n",
        "\n",
        ". . .\n",
        "\n",
        "$$\n",
        "A=\\left[\\mathbf{w}_{1}, \\mathbf{w}_{2}, \\mathbf{w}_{3}\\right]=\\left[\\mathbf{q}_{1}, \\mathbf{q}_{2}, \\mathbf{q}_{3}\\right]\\left[\\begin{array}{ccc}\n",
        "1 & \\frac{\\mathbf{q}_{1} \\cdot \\mathbf{w}_{2}}{\\mathbf{q}_{1} \\cdot \\mathbf{q}_{1}} & \\frac{\\mathbf{q}_{1} \\cdot \\mathbf{w}_{3}}{\\mathbf{q}_{1} \\cdot \\mathbf{q}_{1}} \\\\\n",
        "0 & 1 & \\frac{\\mathbf{q}_{2} \\cdot \\mathbf{w}_{3}}{\\mathbf{q}_{2} \\cdot \\mathbf{q}_{2}} \\\\\n",
        "0 & 0 & 1\n",
        "\\end{array}\\right]\n",
        "$$\n",
        "\n",
        "## *Haar Wavelets*\n",
        "\n",
        "(ch4 lecture 2)\n",
        "\n",
        "# *Chapter 5: Eigenvalues and Eigenvectors*\n",
        "\n",
        "## *Eigenvalues and Eigenvectors*\n",
        "\n",
        "(ch5 lecture 1) - Definition - \\*How to find them - Similarity and\n",
        "Diagonalization - Applications to dynamical systems - Spectral radius\n",
        "\n",
        "### *Finding Eigenvalues and Eigenvectors*\n",
        "\n",
        "If $A$ is a square $n \\times n$ matrix, the equation\n",
        "$\\operatorname{det}(\\lambda I-A)=0$ is called the **characteristic\n",
        "equation** of $A$\n",
        "\n",
        "The eigenvalues of $A$ are the roots of the characteristic equation.\n",
        "\n",
        "For each scalar $\\lambda$ in (1), use the null space algorithm to find a\n",
        "basis of the eigenspace $\\mathcal{N}(\\lambda I-A)$.\n",
        "\n",
        "## *Symmetric matrices*\n",
        "\n",
        "(ch5 lecture 2)\n",
        "\n",
        "-   Properties of symmetric matrices\n",
        "-   Quadratic forms\n",
        "\n",
        "## *SVD*\n",
        "\n",
        "(ch5 lecture 3, 4)\n",
        "\n",
        "-   Definition\n",
        "-   \\*Psuedoinverse\n",
        "-   Applications to least squares\n",
        "-   Image compression\n",
        "\n",
        "### *Pseudoinverse*\n",
        "\n",
        "The **pseudoinverse** of $A$ is $A^{+}=V S^+ U^{T}$\n",
        "\n",
        "$S^{+}$ is the matrix with the reciprocals of the non-zero singular\n",
        "values on the diagonal, and zeros elsewhere.\n",
        "\n",
        ". . .\n",
        "\n",
        "Can find least squares solutions:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "A x & =b \\\\\n",
        "x & \\approx A^{+} b\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "## *PCA*\n",
        "\n",
        "(ch5 lecture 5)\n",
        "\n",
        "-   Definition\n",
        "-   Applications to data analysis\n",
        "\n",
        "# *Chapter 6: Fourier Transform*\n",
        "\n",
        "## *Fourier Transform*\n",
        "\n",
        "(ChNone, Ch6 lecture 1)"
      ],
      "id": "b6801708-9767-45b1-949f-c6682e905064"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  }
}