---
title: Ch5 Lecture 4
lecture_day: 14
readings: ""
publish: false
execute: 
  cache: false
lightbox: true
filters:
    - pyodide
kernel: jupyter
format: 
    course-presentation-revealjs:
      css: theorem.css
      code-fold: show
---

Really cool demo of SVD image compression:
https://timbaumann.info/svd-image-compression-demo/



Remember the left singular values are the eigenvalues of $A^TA$ and the right singular values are the eigenvalues of $AA^T$.

For an image, $A^TA$ is the covariance matrix of the columns of $A$ and $AA^T$ is the covariance matrix of the rows of $A$.

```{python}
import sympy as sp
from sympy import latex,N
from IPython.display import display, Math, Markdown
A = sp.Matrix([[1, 2], [3, 4], [5, 6]])

ata = A.T*A
aat = A*A.T
e1 = ata.eigenvects()[0][2][0]
e2 = ata.eigenvects()[1][2][0]
d1 = aat.eigenvects()[0][2][0]
d2 = aat.eigenvects()[1][2][0]
d3 = aat.eigenvects()[2][2][0]
ev1 = N(ata.eigenvects()[0][0],2)
ev2 = N(ata.eigenvects()[1][0],2)
dv1 = N(aat.eigenvects()[0][0],2)
dv2 = N(aat.eigenvects()[1][0],2)
dv3 = N(aat.eigenvects()[2][0],2)

```

```{python}
def pv(x):
    return(Markdown(latex(x,itex=True,mode='inline')))
```

For $A^TA$ = `{python} pv(ata)`, the eigenvectors are: 

1. `{python} pv(e1)` with eigenvalue `{python} pv(ev1)`
2. `{python} pv(e2)` with eigenvalue `{python} pv(ev2)`

For $AA^T$ = `{python} pv(aat)`, the eigenvectors are:

1. `{python} pv(d1)` with eigenvalue `{python} pv(dv1)`
2. `{python} pv(d2)` with eigenvalue `{python} pv(dv2)`
3. `{python} pv(d3)` with eigenvalue `{python} pv(dv3)`








What does the covariance of the columns mean? It captures when two columns are correlated. If two columns are correlated, then the corresponding singular value will be large. If two columns are not correlated, then the corresponding singular value will be small.

So an eigenvector of the covariance matrix of the columns of $A$ is a vector that has a similar pattern to the actual columns of $A$.

