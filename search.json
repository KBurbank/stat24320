[
  {
    "objectID": "notebooks/turing_patterns.html",
    "href": "notebooks/turing_patterns.html",
    "title": "Turing Patterns",
    "section": "",
    "text": "Adapted from ijmbarr"
  },
  {
    "objectID": "notebooks/turing_patterns.html#reaction-diffusion-equations",
    "href": "notebooks/turing_patterns.html#reaction-diffusion-equations",
    "title": "Turing Patterns",
    "section": "Reaction Diffusion Equations",
    "text": "Reaction Diffusion Equations\nReaction-Diffusion equations are a class of partial differential equations whose dynamics are governed by two terms: a diffusion part and a reaction part. We will be looking at the two component case, which takes the form\n\\(\\frac{\\partial a(x,t)}{\\partial t} = D_{a}\\frac{\\partial^{2} a(x,t)}{\\partial x^{2}} + R_{a}(a(x,t),b(x,t))\\)\n\\(\\frac{\\partial b(x,t)}{\\partial t} = D_{b}\\frac{\\partial^{2} b(x,t)}{\\partial x^{2}} + R_{b}(a(x,t),b(x,t))\\)\nWhere the \\(a(x,t)\\) and \\(b(x,t)\\) describe the concentration of chemicals \\(a\\) and \\(b\\) at position \\(x\\) and time \\(t\\). The functions \\(R_{a}\\) and \\(R_{b}\\) determine how the concentrations change due to interspecies reactions and \\(D_{a}\\) and \\(D_{b}\\) are the diffusion coefficients.\n\nDiffusion\nThe diffusion part of the equations causes areas of high concentration to spread out to areas of low concentration, while conserving the total amount of the chemical. To get a feel for what’s happening, let’s focus the equation\n$ = D_{a} $\nIf this looks familiar, it is because it appears in a number of different areas of science and maths. A few are: the diffusion equation, the heat equation and Brownian motion.\nIt has an analytic solution, which for initial Gaussian distribution is\n$ a(x,t) = (-)$\nA “spreading out”, or diffusion over time, as the name suggests.\n\n\nSimulating equations\nIf you’ve got this far, you might have noticed that this is written in a jupyter notebook. This allows us to mix code with writing, so we don’t just have to look at an equation to understand how it behaves - we can simulate it directly.\nTo simulate the PDEs, I’m going to use the explicit finite-difference method. It is not the best numerical method to use, but it is easy to code, and provided we keep the time step small enough it will be stable.\nUnder this scheme, we approximate the time derivative as\n\\[\n\\frac{\\partial a(x,t)}{\\partial t} \\approx \\frac{1}{dt}(a_{x,t+1} - a_{x,t})\n\\]\nAnd the spatial part of the derivative (which is usually know as the Laplacian) as\n\\[\n\\frac{\\partial^{2} a(x,t)}{\\partial x^{2}} \\approx \\frac{1}{dx^{2}}(a_{x+1,t} + a_{x-1,t} - 2a_{x,t})\n\\]\nPutting it all together, for the diffusion part of the equation we get.\n\\[\na_{x,t+1} = a_{x,t} + dt\\left(  \\frac{D_{a}}{dx^{2}}(a_{x+1,t} + a_{x-1,t} - 2a_{x,t})  \\right)\n\\]\nLet’s start by defining some functions to take care of the spatial derivatives. We will be using periodic boundary conditions throughout our exploration, which are easy to implement in numpy using its roll function.\n\n\nimport httpimport\nwith httpimport.github_repo('ijmbarr','turing-patterns'):\n  import tutils\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# I'm using seaborn for it's fantastic default styles\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\n%matplotlib inline\n%load_ext autoreload\n%autoreload 2\n\nfrom tutils import BaseStateSystem\n\n\ndef laplacian1D(a, dx):\n    return (\n        - 2 * a\n        + np.roll(a,1,axis=0)\n        + np.roll(a,-1,axis=0)\n    ) / (dx ** 2)\n\ndef laplacian2D(a, dx):\n    return (\n        - 4 * a\n        + np.roll(a,1,axis=0)\n        + np.roll(a,-1,axis=0)\n        + np.roll(a,+1,axis=1)\n        + np.roll(a,-1,axis=1)\n    ) / (dx ** 2)\n\nTo aid in generating visualisations, I’ve written a base class which updates and plots a system based on some notion of state. There’s nothing specific about the reaction diffusion equations encoded in it, so I’m not going to go into any detail about it. You can find the full code for it, along with this notebook on github here. It uses matplotlib’s animation functionality to plot the output as a gif.\nAll together we can simulate the effect of the diffusion equation:\n\nclass OneDimensionalDiffusionEquation(BaseStateSystem):\n    def __init__(self, D):\n        self.D = D\n        self.width = 1000\n        self.dx = 10 / self.width\n        self.dt = 0.9 * (self.dx ** 2) / (2 * D)\n        self.steps = int(0.1 / self.dt)\n\n    def initialise(self):\n        self.t = 0\n        self.X = np.linspace(-5,5,self.width)\n        self.a = np.exp(-self.X**2)\n\n    def update(self):\n        for _ in range(self.steps):\n            self.t += self.dt\n            self._update()\n\n    def _update(self):\n        La = laplacian1D(self.a, self.dx)\n        delta_a = self.dt * (self.D * La)\n        self.a += delta_a\n\n    def draw(self, ax):\n        ax.clear()\n        ax.plot(self.X,self.a, color=\"r\")\n        ax.set_ylim(0,1)\n        ax.set_xlim(-5,5)\n        ax.set_title(\"t = {:.2f}\".format(self.t))\n\none_d_diffusion = OneDimensionalDiffusionEquation(D=1)\n\none_d_diffusion.plot_time_evolution(\"diffusion.gif\")\n\nMovieWriter imagemagick unavailable; using Pillow instead.\n\n\n\n\n\ndiffusion\n\n\nAs expected - the diffusion equation causes the the concentration to “spread out”.\n\n\nReaction\nInteractions between the two chemical components are introduced via the functions \\(R_{a}\\) and \\(R_{b}\\). These functions only depend on the local concentration of each of the chemicals. Their exact form will depend on the chemicals involved, but it is possible to show that Turing patterns are observed for a whole class of different equations.\nThe one thing we will require from these equations is that they reach a stable equilibrium when the concentrations of the chemicals involved are completely homogeneous. This means that there exists concentrations of \\(a\\) and \\(b\\) such that\n\\(R_a(a_{0}, b_{0}) = 0\\)\n\\(R_{b}(a_{0}, b_{0}) = 0\\)\nThe fact that we require this to hold will make the later instability more suprising.\nFor the reaction equations, I’m going to use the FitzHugh–Nagumo equation\n\\(R_a(a, b) = a - a^{3} - b + \\alpha\\)\n\\(R_{b}(a, b) = \\beta (a - b)\\)\nWhere \\(\\alpha\\) and \\(\\beta\\) are constants.\nLet’s see how it behaves\n\nclass ReactionEquation(BaseStateSystem):\n    def __init__(self, Ra, Rb):\n        self.Ra = Ra\n        self.Rb = Rb\n        self.dt = 0.01\n        self.steps = int(0.1 / self.dt)\n\n    def initialise(self):\n        self.t = 0\n        self.a = 0.1\n        self.b = 0.7\n        self.Ya = []\n        self.Yb = []\n        self.X = []\n\n    def update(self):\n        for _ in range(self.steps):\n            self.t += self.dt\n            self._update()\n\n    def _update(self):\n        delta_a = self.dt * self.Ra(self.a,self.b)\n        delta_b = self.dt * self.Rb(self.a,self.b)\n\n        self.a += delta_a\n        self.b += delta_b\n\n    def draw(self, ax):\n        ax.clear()\n\n        self.X.append(self.t)\n        self.Ya.append(self.a)\n        self.Yb.append(self.b)\n\n        ax.plot(self.X,self.Ya, color=\"r\", label=\"A\")\n        ax.plot(self.X,self.Yb, color=\"b\", label=\"B\")\n        ax.legend()\n\n        ax.set_ylim(0,1)\n        ax.set_xlim(0,5)\n        ax.set_xlabel(\"t\")\n        ax.set_ylabel(\"Concentrations\")\n\nalpha, beta =  0.2, 5\n\ndef Ra(a,b): return a - a ** 3 - b + alpha\ndef Rb(a,b): return (a - b) * beta\n\none_d_reaction = ReactionEquation(Ra, Rb)\none_d_reaction.plot_time_evolution(\"reaction.gif\", n_steps=50)\n\nMovieWriter imagemagick unavailable; using Pillow instead.\n\n\n\n\n\nreaction\n\n\nThe system is stable, and stabilises to \\(a = b = \\sqrt[3]{\\alpha}\\)."
  },
  {
    "objectID": "notebooks/turing_patterns.html#full-model",
    "href": "notebooks/turing_patterns.html#full-model",
    "title": "Turing Patterns",
    "section": "Full Model",
    "text": "Full Model\nWe now have two parts to the reaction diffusion equation: a diffusion term that “spreads” out concentration and a reaction part the equalises the two concentrations. It feels like these two together should create a stable system, so it is surprising that we can end up with patterns.\nBut enough with the preliminaries, let’s take a look at some of the patterns formed.\n\ndef random_initialiser(shape):\n    return(\n        np.random.normal(loc=0, scale=0.05, size=shape),\n        np.random.normal(loc=0, scale=0.05, size=shape)\n    )\n\nclass OneDimensionalRDEquations(BaseStateSystem):\n    def __init__(self, Da, Db, Ra, Rb,\n                 initialiser=random_initialiser,\n                 width=1000, dx=1,\n                 dt=0.1, steps=1):\n\n        self.Da = Da\n        self.Db = Db\n        self.Ra = Ra\n        self.Rb = Rb\n\n        self.initialiser = initialiser\n        self.width = width\n        self.dx = dx\n        self.dt = dt\n        self.steps = steps\n\n    def initialise(self):\n        self.t = 0\n        self.a, self.b = self.initialiser(self.width)\n\n    def update(self):\n        for _ in range(self.steps):\n            self.t += self.dt\n            self._update()\n\n    def _update(self):\n\n        # unpack so we don't have to keep writing \"self\"\n        a,b,Da,Db,Ra,Rb,dt,dx = (\n            self.a, self.b,\n            self.Da, self.Db,\n            self.Ra, self.Rb,\n            self.dt, self.dx\n        )\n\n        La = laplacian1D(a, dx)\n        Lb = laplacian1D(b, dx)\n\n        delta_a = dt * (Da * La + Ra(a,b))\n        delta_b = dt * (Db * Lb + Rb(a,b))\n\n        self.a += delta_a\n        self.b += delta_b\n\n    def draw(self, ax):\n        ax.clear()\n        ax.plot(self.a, color=\"r\", label=\"A\")\n        ax.plot(self.b, color=\"b\", label=\"B\")\n        ax.legend()\n        ax.set_ylim(-1,1)\n        ax.set_title(\"t = {:.2f}\".format(self.t))\n\nDa, Db, alpha, beta = 1, 100, -0.005, 10\n\ndef Ra(a,b): return a - a ** 3 - b + alpha\ndef Rb(a,b): return (a - b) * beta\n\nwidth = 100\ndx = 1\ndt = 0.001\n\nOneDimensionalRDEquations(\n    Da, Db, Ra, Rb,\n    width=width, dx=dx, dt=dt,\n    steps=100\n).plot_time_evolution(\"1dRD.gif\", n_steps=150)\n\nMovieWriter imagemagick unavailable; using Pillow instead.\n\n\n\n\n\nreaction\n\n\nA pattern of stripes.\nWe can see that same behavior in two dimensions:\n\nclass TwoDimensionalRDEquations(BaseStateSystem):\n    def __init__(self, Da, Db, Ra, Rb,\n                 initialiser=random_initialiser,\n                 width=1000, height=1000,\n                 dx=1, dt=0.1, steps=1):\n\n        self.Da = Da\n        self.Db = Db\n        self.Ra = Ra\n        self.Rb = Rb\n\n        self.initialiser = initialiser\n        self.width = width\n        self.height = height\n        self.shape = (width, height)\n        self.dx = dx\n        self.dt = dt\n        self.steps = steps\n\n    def initialise(self):\n        self.t = 0\n        self.a, self.b = self.initialiser(self.shape)\n\n    def update(self):\n        for _ in range(self.steps):\n            self.t += self.dt\n            self._update()\n\n    def _update(self):\n\n        # unpack so we don't have to keep writing \"self\"\n        a,b,Da,Db,Ra,Rb,dt,dx = (\n            self.a, self.b,\n            self.Da, self.Db,\n            self.Ra, self.Rb,\n            self.dt, self.dx\n        )\n\n        La = laplacian2D(a, dx)\n        Lb = laplacian2D(b, dx)\n\n        delta_a = dt * (Da * La + Ra(a,b))\n        delta_b = dt * (Db * Lb + Rb(a,b))\n\n        self.a += delta_a\n        self.b += delta_b\n\n    def draw(self, ax):\n        ax[0].clear()\n        ax[1].clear()\n\n        ax[0].imshow(self.a, cmap='jet')\n        ax[1].imshow(self.b, cmap='brg')\n\n        ax[0].grid(visible=False)\n        ax[1].grid(visible=False)\n\n        ax[0].set_title(\"A, t = {:.2f}\".format(self.t))\n        ax[1].set_title(\"B, t = {:.2f}\".format(self.t))\n\n    def initialise_figure(self):\n        fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,6))\n        return fig, ax\n\nDa, Db, alpha, beta = 1, 100, -0.015, 10\n\ndef Ra(a,b): return a - a ** 3 - b + alpha\ndef Rb(a,b): return (a - b) * beta\n\nwidth = 100\ndx = 1\ndt = 0.001\n\nTwoDimensionalRDEquations(\n    Da, Db, Ra, Rb,\n    width=width, height=width,\n    dx=dx, dt=dt, steps=100\n).plot_evolution_outcome(\"2dRD.png\", n_steps=150)\n\n\n\n\nreaction\n\n\n(It is possible to animate the formation of these patterns using a similar method call as in the one-dimensional case above. The resulting gifs are quite impressive, but also large, so they are not directly included here. However, if you click on the image it will take you to the animation)\nIt turns out this behaviour is common to a lot of reaction-diffusion equations, not just the ones presented here.\nSo how does this happen? To understand, we are going to need to do some maths."
  },
  {
    "objectID": "notebooks/turing_patterns.html#stability-analysis",
    "href": "notebooks/turing_patterns.html#stability-analysis",
    "title": "Turing Patterns",
    "section": "Stability Analysis",
    "text": "Stability Analysis\nLet’s return to the original equations. We’ve seen that for certain conditions, pattern formations occurs.\nUnfortunately, solving the equations directly for non-linear reaction functions is often not possible. Instead we can look at what happens when the the system is perturbed slightly from equilibrium.\n\nLinearising the Equations\nWe start by assuming there is some concentrations, \\(a_{0}\\) and \\(b_{0}\\), for which the system is stable. This means that - \\(R_{a}(a_{0},b_{0}) = 0\\) - \\(R_{b}(a_{0},b_{0}) = 0\\)\nAround these solutions, we look at the time dependence of small perturbations around these values - \\(x = a - a_{0}\\) - \\(y = b - b_{0}\\)\nAnd linearise the reaction equations - \\(R_{a}(a,b) \\approx r_{aa}x + r_{ab}y\\) - \\(R_{b}(a,b) \\approx r_{ba}x + r_{bb}y\\)\nwhere \\(r_{ij} = \\frac{\\partial R_{i}}{\\partial j}\\).\nThese approximations give us a set of linear equations, written in vector form as\n\\(\\dot{\\mathbf{x}} = D\\nabla^{2} \\mathbf{x} + R \\mathbf{x}\\)\nWhere \\(R = \\left(\\begin{matrix} r_{11} & r_{12} \\\\ r_{21} & r_{22}\\end{matrix}\\right)\\) and \\(D = \\left(\\begin{matrix} D_{a} & 0 \\\\ 0 & D_{b}\\end{matrix}\\right)\\)\n\n\nFourier Transform\nIf we impose periodic boundary conditions to this equation, a natural solution can be found by applying a Fourier Transformation to \\(\\mathbf{x}\\). If we call the reciprocal coordinate \\(k\\), and the Fourier transform of \\(\\mathbf{x}\\) as \\(\\tilde{\\mathbf{x}}\\), then the transformed equation is\n\\(\\dot{\\tilde{\\mathbf{x}}} = (R - k^{2}D) \\tilde{\\mathbf{x}}\\)\nWhich, has solutions of the form\n\\(\\tilde{\\mathbf{x}}(t) = \\tilde{\\mathbf{x}}(0) e^{\\omega t}\\)\nTo find \\(\\omega\\) we plug this solution back into our transformed equation to get\n\\(\\omega \\tilde{\\mathbf{x}} = (R - k^{2}D) \\tilde{\\mathbf{x}}\\)\nShowing that \\(\\omega\\) is just the eigenvalue of \\((R - k^{2}D)\\).\n\n\nStability\nWe now have an equation for the time dependence of our system in the Fourier domain. Using it, we can now discuss what we mean by stability. Our system is considered stable if small perturbations around the homogeneous do not cause it to move further away from the stable solutions.\nIn terms of our solution, \\(\\tilde{\\mathbf{x}}(0) e^{\\omega t}\\), stability means that the values of \\(\\omega\\) does not have positive real parts for all values of \\(k\\). If \\(\\omega\\) is negative, the perturbation will decay away. If \\(\\omega\\) is imaginary, it will oscillate around the stable state. However, if it is positive and real any small perturbation will grow exponentially, until a high order term of the reaction equation becomes important.\nTo find \\(\\omega\\), we need to solve the equation\n$(R - k^{2}D - I) = 0 $\nWriting \\(J = R - k^{2}D\\), this equitation takes the form\n\\(\\omega^{2} - \\omega\\hbox{Tr}(J) + \\hbox{Det}(J) = 0\\)\nSolving for \\(\\omega\\), we get\n\\(\\omega = \\frac{1}{2}(\\hbox{Tr}(J) \\pm \\sqrt{\\hbox{Tr}(J)^{2} - 4 \\hbox{Det}(J) })\\)\n\n\nConditions for (in)Stability\nFrom our initial assumption that there was a stable homogeneous state, we require that \\(\\omega\\) has negative real parts where \\(k = 0\\), which corresponds to the spatially homogeneous solution. For this to be true, we require that\n\n\\(\\hbox{Tr}(R) &lt; 0\\)\n\\(\\hbox{det}(R) &gt; 0\\)\n\nOr, in terms of the components of \\(R\\): - \\(r_{aa} + r_{bb} &lt; 0\\) - \\(r_{aa}r_{bb} - r_{ab}r_{ba} &gt; 0\\)\nFor an instability to now occur at finite wavelength, we need one of the following conditions to hold: - \\(\\hbox{Tr}(J) &gt; 0\\) - \\(\\hbox{det}(J) &lt; 0\\)\nBecause \\(\\hbox{Tr}(J) = \\hbox{Tr}(R) - k^{2}(d_{a} + d_{b})\\), the first condition cannot hold for any real \\(k\\). This means the we require the second to hold, or, after a bit of algebra\n\\(k^{4}d_{a}d_{b} - k^{2}(d_{a}r_{bb} + d_{b}r_{aa}) + (r_{aa}r_{bb} - r_{ab}r_{ba}) &lt; 0\\)\nfor some real value of \\(k\\). Once again, we need to solve a quadratic equation. To do this we note that because \\(k\\) needs to be real, \\(k^{2}\\) must be positive. This means that at least one root of quadratic equation in \\(k^{2}\\) needs to be positive and real. This condition is only met when\n\\(d_{b}r_{aa} + d_{a}r_{bb} &gt; 2\\sqrt{d_{a}d_{b}(r_{aa}r_{bb} - r_{ab}r_{ba})} &gt; 0\\)\nAnd that’s it. We’ve derived that conditions for the diffusion-reaction equations to be stable to small perturbations.\nWe can write the complete requirements as\n\n\\(r_{aa} + r_{bb} &lt; 0\\)\n\\(r_{aa}r_{bb} - r_{ab}r_{ba} &gt; 0\\)\n\\(d_{b}r_{aa} + d_{a}r_{bb} &gt; 2\\sqrt{d_{a}d_{b}(r_{aa}r_{bb} - r_{ab}r_{ba})} &gt; 0\\)\n\n\n\nDiscussion\nWe’ve waded through a lot of maths to reach this point. Let’s take stock of what we can make of the conditions for instability that we have derived.\nGiven the diffusion coefficients are positive, from the first and third equation above, we know that \\(r_{aa}\\) and \\(r_{bb}\\) have to have different signs, and the component with the negative sign has to be larger. Combining this we the second equation we know that either \\(r_{ab}\\) or \\(r_{ba}\\) has to be negative, and the other has to be positive. This two facts show why some systems like this are called activator-inhibitor system: the presence of one component increase the production of itself - the other inhibits the production of both.\nWith this information, the third equation shows us that the diffusion coefficients need to be different. Specifically, the diffusion coefficient of the inhibitor has to be larger then that of the activator.\nTogether, this gives us a hand-waving explanation of what might be going on: Consider starting with a small increase in the activator at some point. This in turn creates an increase in the inhibitor at that point. Both of these chemical diffuse to nearby points, but the inhibitor diffuses faster, lowering the activator concentration of nearby points. This lowering of the activator concentration at nearby points, which in turn lowers the inhibitor concentration. The disturbance spreads out like a wave.\nIt is a lot easier to get a feel for what’s going on once we visualise the this perturbation:\n\nDa, Db, alpha, beta = 1, 100, -0.005, 10\n\ndef Ra(a,b): return a - a ** 3 - b + alpha\ndef Rb(a,b): return (a - b) * beta\n\ndef initalise_bump(shape):\n    a  = np.zeros(shape)\n    if len(a.shape) == 1:\n        a[int(a.shape[0] / 2)] = 0.3\n    elif len(a.shape) == 2:\n        a[int(a.shape[0] / 2), int(a.shape[1] / 2)] = 0.3\n\n    return(\n        a,\n        np.zeros(shape)\n    )\n\nwidth = 100\ndx = 1\ndt = 0.001\n\nOneDimensionalRDEquations(\n    Da, Db, Ra, Rb,\n    initialiser=initalise_bump,\n    width=width, dx=dx, dt=dt,\n    steps=250\n).plot_time_evolution(\"1dRD_initial_bump.gif\", n_steps=150)\n\n\n\n\nreaction\n\n\n\n\nExploring the Parameter Space\nIt is interesting to ask how the parameters of the equations affect the pattern formation. To get a feel for what this dependence is, we can investigate the amplitude of the instability for different frequencies. Close to equilibrium, we expect the frequency with the largest real component to dominate the dynamics of the system.\nCalculating this value isn’t mathematically difficult: we have an equation of the amplitude \\(\\omega\\) in terms of the frequency \\(k\\) above. Differentiating an equation of this size by hand can become tedious due to its size, and it is easy to introduce errors. And why carry out simple replacement steps when we have a computer to hand?\nIn the following, I use the computer algebra system sympy to find the largest real mode of the system\n\nimport sympy as sp\nsp.init_printing()\n\n# define symbols\na,b,alpha,beta = sp.symbols(\"a,b,alpha,beta\")\nRaa, Rab, Rba, Rbb = sp.symbols(\"Raa, Rab, Rba, Rbb\")\nDa, Db = sp.symbols(\"Da, Db\")\nk2 = sp.Symbol(\"k2\")\n\n# create matricies\nR = sp.Matrix(\n    [[Raa, Rab],\n     [Rba, Rbb]]\n)\n\nD = sp.Matrix(\n    [[Da, 0],\n     [0, Db]]\n)\n\nJ = (R - k2 * D)\n\n# define our solution for omega\nomega = sp.Matrix.trace(J) + sp.sqrt(sp.Matrix.trace(J) ** 2 - 4 * sp.Matrix.det(J))\nomega\n\n\\[- Da k_{2} - Db k_{2} + Raa + Rbb + \\sqrt{- 4 Da Db k_{2}^{2} + 4 Da Rbb k_{2} + 4 Db Raa k_{2} - 4 Raa Rbb + 4 Rab Rba + \\left(- Da k_{2} - Db k_{2} + Raa + Rbb\\right)^{2}}\\]\n\n\n\n# find the maximum value of omega for k^{2}\nomega_prime = sp.diff(omega, k2)\nsols = sp.solvers.solve(omega_prime, k2)\nmax_k2 = sols[0]\n\nmax_k2\n\n\\[\\frac{1}{Da Db \\left(Da - Db\\right)} \\left(Da Db Raa - Da Db Rbb - Da \\sqrt{- Da Db Rab Rba} - Db \\sqrt{- Da Db Rab Rba}\\right)\\]\n\n\n\ndef get_length_scale(al, be, da, db):\n\n    # rewritng in terms of Da, Db, alpha, beta\n    Ra = a - a**3 - b + alpha\n    Rb = beta * (a - b)\n\n    # we expand around the homogenius steady state\n    zero_subs = [\n        (a, sp.sign(alpha) * sp.cbrt(sp.Abs(alpha))),\n        (b, sp.sign(alpha) * sp.cbrt(sp.Abs(alpha)))\n    ]\n\n    # and linearise\n    R_prime_subs = {\n        (Raa, sp.diff(Ra, a)),\n        (Rab, sp.diff(Ra, b)),\n        (Rba, sp.diff(Rb, a)),\n        (Rbb, sp.diff(Rb, b))\n    }\n\n    # putting in our numeric values we get\n    vals = [\n        (alpha, al),\n        (beta, be),\n        (Da, da),\n        (Db, db)\n    ]\n\n    # substitute it all in to find the maximum k\n    max_k2 = [sp.N(\n        sol\n        .subs(R_prime_subs)\n        .subs(zero_subs)\n        .subs(vals)\n    ) for sol in sols]\n\n    k2 = max(sp.re(sym) for sym in max_k2)\n\n    # if k2 is negative, no real solution exists\n    if k2 &lt;= 0:\n        return -1\n\n    # convert k2 into length units\n    return sp.N(2 * sp.pi / sp.sqrt(k2))\n\nget_length_scale(-0.005, 10, 1, 100)\n\n\\[13.6336345738685\\]\n\n\nWhich looks about right when we compare it to our simulations above - the spatial variation is about 14 length units.\nLet’s use it to see how the length scale of the system changes as a function of \\(\\alpha\\) and \\(\\beta\\):\n\nbetas = [(1 + i) * 0.125 for i in range(0,40)]\nalphas = [i * 0.05 for i in range(-20,20)]\n\noutcomes = np.zeros((len(betas), len(alphas)))\n\nfor x,al in enumerate(alphas):\n    for y,be in enumerate(betas):\n        outcomes[y,x] = get_length_scale(al, be, 1, 100)\n\n\nplt.figure(figsize=(8,8))\n\no = outcomes\no[outcomes == 0] = -1\n\nplt.imshow(o, cmap=\"hsv\", interpolation=\"none\")\nplt.colorbar()\n\nplt.xticks(*zip(*[(n,l) for n,l in enumerate(alphas) if n % 5 == 0]), rotation=90)\nplt.yticks(*zip(*[(n,l) for n,l in enumerate(betas) if n % 5 == 0]), rotation=0)\n\nplt.title(\"Lengthscale\", fontsize=20)\nplt.xlabel(r\"$\\alpha$\", fontsize=18)\nplt.ylabel(r\"$\\beta$\", fontsize=18);\n\n\n\n\n\n\n\n\nAnd take a look at the long length scale we should see when we use a low value of \\(\\beta\\):\n\nDa, Db, alpha, beta = 1, 100, 0.01, 0.25\n\ndef Ra(a,b): return a - a ** 3 - b + alpha\ndef Rb(a,b): return (a - b) * beta\n\nwidth = 200\ndx = 1\ndt = 0.001\n\nTwoDimensionalRDEquations(\n    Da, Db, Ra, Rb,\n    width=width, height=width,\n    dx=dx, dt=dt, steps=150\n).plot_evolution_outcome(\"2dRD_small_beta.png\", n_steps=100)\n\n\n\n\nreaction\n\n\n\n\nInitial Conditions\nAdjusting the parameters gives us control over the length scale of the system. We can also gain some control over the system by adjusting the initial conditions of the system. For example, we can impose symmetries on the system by making the initial conditions symmetric:\n\nfrom scipy.ndimage.interpolation import rotate\n\ndef average_rotate(a, degree):\n    \"\"\"\n    Takes a 2d array a, and produces the average arrays,\n    having rotated it degree times. The resulting shape\n    has approximate degree-fold rotational symmetry.\n    \"\"\"\n    theta = 360 / degree\n\n    a = np.mean([rotate(a, theta * i, reshape=False) for i in range(degree)], axis=0)\n\n    return a\n\n\ndef random_symmetric_initialiser(shape, degree):\n    \"\"\"\n    Random initialiser with degree-fold symmetry.\n    \"\"\"\n\n    a = np.random.normal(loc=0, scale=0.05, size=shape)\n    b = np.random.normal(loc=0, scale=0.05, size=shape)\n\n    return (\n        average_rotate(a, degree),\n        average_rotate(b, degree)\n    )\n\nDa, Db, alpha, beta = 1, 100, 0.01, 1\n\ndef Ra(a,b): return a - a ** 3 - b + alpha\ndef Rb(a,b): return (a - b) * beta\n\nwidth = 200\ndx = 1\ndt = 0.001\n\n# three fold\nthree_fold_initialiser = lambda shape: random_symmetric_initialiser(shape, 3)\n\nTwoDimensionalRDEquations(\n    Da, Db, Ra, Rb,\n    initialiser=three_fold_initialiser,\n    width=width, height=width,\n    dx=dx, dt=dt, steps=250\n).plot_evolution_outcome(\"2dRD_3_fold_sym.png\", n_steps=150)\n\n# five fold\nfive_fold_initialiser = lambda shape: random_symmetric_initialiser(shape, 5)\n\nTwoDimensionalRDEquations(\n    Da, Db, Ra, Rb,\n    initialiser=five_fold_initialiser,\n    width=width, height=width,\n    dx=dx, dt=dt, steps=250\n).plot_evolution_outcome(\"2dRD_5_fold_sym.png\", n_steps=150)\n\nThree fold rotational symmetry:\n\n\n\nreaction\n\n\nFive fold rotational symmetry:\n\n\n\nreaction\n\n\nThe symmetry isn’t perfect due to implementing it one a square grid, but it works quite well.\n\n\nSpatial Effects\nAnother interesting extension to these systems is to see what happens when we allow the parameters of the system to vary in space. In our implementation, this is just a matter of making the parameters a grid as well:\n\nDa, Db, alpha, beta = 1, 100, 0.01, 10\n\nwidth = 200\ndx = 1\ndt = 0.001\n\nx,y = np.mgrid[0:width,0:width]\nbeta = 0.1 + 5 * (1 + np.sin(2 * np.pi * y / 50)) * (1 + np.sin(2 * np.pi * x / 50))\n\n\ndef Ra(a,b): return a - a ** 3 - b + alpha\ndef Rb(a,b): return (a - b) * beta\n\nTwoDimensionalRDEquations(\n    Da, Db, Ra, Rb,\n    width=width, height=width,\n    dx=dx, dt=dt, steps=100\n).plot_evolution_outcome(\"2dRD_spatial.png\", n_steps=200)\n\n\n\n\nreaction"
  },
  {
    "objectID": "notebooks/turing_patterns.html#similar-systems",
    "href": "notebooks/turing_patterns.html#similar-systems",
    "title": "Turing Patterns",
    "section": "Similar Systems",
    "text": "Similar Systems\nTuring patterns are only one part of pattern generation from non-linear PDEs. Given we have the tools to explore these systems, it is worth looking at another simple system in which pattern formation occurs: the Gray-Scott equations. As described in the paper Complex Patterns in a Simple System, for an interesting set of initial conditions the Gray-Scott equations result in a range complex patterns being formed.\nWhile these equations are reaction-diffusion equations, the patterns that end up being formed are not from Turing instabilities. Instead they come from the initial conditions of the system: a small region in the centre of the region is perturbed. As this perturbation spreads out, strange patterns are formed.\nTo visualise it, we just need to pass another initialisation function of our previous class, and put in new reaction equations. The parameters for the interesting systems are taken from here. I’m not currently aware of any theory that gives a full explanation of these patterns.\n\ndef gs_initialiser(shape):\n        a = np.ones(shape)\n        b = np.zeros(shape)\n        centre = int(shape[0] / 2)\n\n        a[centre-20:centre+20,centre-20:centre+20] = 0.5\n        b[centre-20:centre+20,centre-20:centre+20] = 0.25\n\n        a += np.random.normal(scale=0.05, size=shape)\n        b += np.random.normal(scale=0.05, size=shape)\n\n        return a,b\n\n# interesting parameters taken from http://www.aliensaint.com/uo/java/rd/\nparams = [\n    [0.16, 0.08, 0.035, 0.065],\n    [0.14, 0.06, 0.035, 0.065],\n    [0.16, 0.08, 0.06, 0.062],\n    [0.19, 0.05, 0.06, 0.062],\n    [0.16, 0.08, 0.02, 0.055],\n    [0.16, 0.08, 0.05, 0.065],\n    [0.16, 0.08, 0.054, 0.063],\n    [0.16, 0.08, 0.035, 0.06]\n]\n\nfor i, param in enumerate(params):\n\n    Da, Db, f, k = param\n\n    def Ra(a,b): return - a*b*b + f*(1-a)\n    def Rb(a,b): return + a*b*b - (f+k)*b\n\n    width = 200\n    dx = 1\n    dt = 1\n\n    TwoDimensionalRDEquations(\n        Da, Db, Ra, Rb,\n        initialiser=gs_initialiser,\n        width=width, height=width,\n        dx=dx, dt=dt, steps=200\n    ).plot_evolution_outcome(\"gs_{}.png\".format(i), n_steps=100)\n\n\n\n\nreaction\n\n\n\n\n\nreaction\n\n\n\n\n\nreaction\n\n\n\n\n\nreaction\n\n\n\n\n\nreaction\n\n\n\n\n\nreaction\n\n\n\n\n\nreaction\n\n\n\n\n\nreaction"
  },
  {
    "objectID": "notebooks/turing_patterns.html#conclusion",
    "href": "notebooks/turing_patterns.html#conclusion",
    "title": "Turing Patterns",
    "section": "Conclusion",
    "text": "Conclusion\nIt’s been interesting to play with these non-linear systems. One of the main challenges I’ve found with looking at them is how you find “interesting” parameters. I have some ideas about how we might search for these automatically, but that will have to wait for another post.\nThe complexity that can arise from these simple systems surprised me at fist, but it has been shown that it is possible to encode cellular automata in reaction diffusion systems. This suggests that the patterns formed by reaction-diffusion systems can be as complex as those produced by any Turing-complete system, and that any attempt to provide a quantitative explanation for their full behaviour will eventually run into some undecidable statement.\nAnd with that connection between Turing’s work on reaction-diffusion equations and his more well known work on computability, I think it’s time to end this post."
  },
  {
    "objectID": "notebooks/turing_patterns.html#code",
    "href": "notebooks/turing_patterns.html#code",
    "title": "Turing Patterns",
    "section": "Code",
    "text": "Code\nThis post was created from a jupyter notebook. You can find it here."
  },
  {
    "objectID": "lectures/test.html#a-slide",
    "href": "lectures/test.html#a-slide",
    "title": "a test",
    "section": "A slide",
    "text": "A slide\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/ch1_lecture2.html#a-resource-for-review",
    "href": "lectures/ch1_lecture2.html#a-resource-for-review",
    "title": "More Systems of Linear Equations",
    "section": "A resource for review",
    "text": "A resource for review\nThe glossary from the end of Strand: glossary.pdf"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#systems-with-non-unique-solutions",
    "href": "lectures/ch1_lecture2.html#systems-with-non-unique-solutions",
    "title": "More Systems of Linear Equations",
    "section": "Systems with non-unique solutions",
    "text": "Systems with non-unique solutions\nSolve for the variables \\(x, y\\), and \\(z\\) in the system\n\\[\n\\begin{aligned}\nz & =2 \\\\\nx+y+z & =2 \\\\\n2 x+2 y+4 z & =8\n\\end{aligned}\n\\]\n\nMake an augmented matrix: Example 1.20. Solve for the variables \\(x, y\\), and \\(z\\) in the system\n\\[\n\\left[\\begin{array}{llll}\n0 & 0 & 1 & 2 \\\\\n1 & 1 & 1 & 2 \\\\\n2 & 2 & 4 & 8\n\\end{array}\\right]\n\\]\n\nNote that the first column corresponds to x, the second to y, and the third to z.\n\n\n\n\\[\n\\left[\\begin{array}{llll}\n0 & 0 & 1 & 2 \\\\\n1 & 1 & 1 & 2 \\\\\n2 & 2 & 4 & 8\n\\end{array}\\right] \\stackrel{E_{12}}{\\longrightarrow}\\left[\\begin{array}{llll}\n(1 & 1 & 1 & 2 \\\\\n0 & 0 & 1 & 2 \\\\\n2 & 2 & 4 & 8\n\\end{array}\\right] \\xrightarrow[E_{31}(-2)]{\\longrightarrow}\\left[\\begin{array}{rlll}\n1 & 1 & 1 & 2 \\\\\n0 & 0 & 2 & 4 \\\\\n0 & 0 & 1 & 2\n\\end{array}\\right]\n\\]\n\nNow we are stuck! The first row we are going to use to solve for x. Neither the second or third row tell us anything about y…"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#section",
    "href": "lectures/ch1_lecture2.html#section",
    "title": "More Systems of Linear Equations",
    "section": "",
    "text": "We keep on going… \\[\n\\begin{aligned}\n& {\\left[\\begin{array}{rrrr}\n(1) & 1 & 1 & 2 \\\\\n0 & 0 & 2 & 4 \\\\\n0 & 0 & 1 & 2\n\\end{array}\\right] \\xrightarrow[E_{2}(1 / 2)]{\\longrightarrow}\\left[\\begin{array}{rrrr}\n1 & 1 & 1 & 2 \\\\\n0 & 0 & 1 & 2 \\\\\n0 & 0 & 1 & 2\n\\end{array}\\right]} \\\\\n& \\overrightarrow{E_{32}(-1)}\\left[\\begin{array}{rrrr}\n(1) & 1 & 1 & 2 \\\\\n0 & 0 & 1 & 2 \\\\\n0 & 0 & 0 & 0\n\\end{array}\\right] \\xrightarrow[E_{12}(-1)]{\\longrightarrow}\\left[\\begin{array}{rrrr}\n(1) & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 2 \\\\\n0 & 0 & 0 & 0\n\\end{array}\\right] .\n\\end{aligned}\n\\]\nThere’s still no information on \\(y\\).\n\\[\n\\begin{aligned}\n& x=-y \\\\\n& z=2 \\\\\n& y \\text { is free. }\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#free-versus-bound-variables",
    "href": "lectures/ch1_lecture2.html#free-versus-bound-variables",
    "title": "More Systems of Linear Equations",
    "section": "Free versus bound variables",
    "text": "Free versus bound variables\nSuppose we have another augmented matrix, which after GJ elimination has become:\n\\[\n\\left[\\begin{array}{rrrrr}\nx & y & z & w & \\mathrm{rhs} \\\\\n1 & 2 & 0 & -1 & 2 \\\\\n0 & 0 & 1 & 3 & 0 \\\\\n0 & 0 & 0 & 0 & 0\n\\end{array}\\right] .\n\\]\n\nSolutions are: \\[\n\\begin{aligned}\nx+2 y-w & =2 \\\\\nz+3 w & =0 .\n\\end{aligned}\n\\]\nHow can we tell from looking at the matrix which variables are free vs bound?\nColumns which contain pivots correspond to bound variables. The others correspond to free variables.\n(Columns with pivots are called “basic” columns.)"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#zero-solutions",
    "href": "lectures/ch1_lecture2.html#zero-solutions",
    "title": "More Systems of Linear Equations",
    "section": "Zero solutions",
    "text": "Zero solutions\nSolve this system… \\[\n\\begin{array}{r}\nx+y=1 \\\\\n2 x+y=2 \\\\\n3 x+2 y=5 .\n\\end{array}\n\\]\n\n\\[\n\\left[\\begin{array}{lll}\n1 & 1 & 1 \\\\\n2 & 1 & 2 \\\\\n3 & 2 & 5\n\\end{array}\\right] \\xrightarrow[E_{21}(-2)]{E_{31}(-3)}\\left[\\begin{array}{lrl}\n1 & 1 & 1 \\\\\n0 & -1 & 0 \\\\\n0 & -1 & 2\n\\end{array}\\right] \\xrightarrow[E_{32}(-1)]{\\longrightarrow}\\left[\\begin{array}{rrr}\n1 & 1 & 1 \\\\\n0 & -1 & 0 \\\\\n0 & 0 & 2\n\\end{array}\\right]\n\\]\n\nWe didn’t even finish the G-J elimination, but there’s clearly a problem. We can’t have 0 = 2. Maybe not a surprise, since we have three equations with only two unknowns!\n\n\n\nSystem is inconsistent."
  },
  {
    "objectID": "lectures/ch1_lecture2.html#consistency",
    "href": "lectures/ch1_lecture2.html#consistency",
    "title": "More Systems of Linear Equations",
    "section": "Consistency",
    "text": "Consistency\nFor an augmented matrix in RREF, if the only only nonzero entry in a row appears on the right-hand side,\n\\[\\text { Row } i \\longrightarrow\\left(\n\\begin{array}{cccccc|c}\n* & * & * & * & * & * & * \\\\\n0 & 0 & 0 & * & * & * & * \\\\\n0 & 0 & 0 & 0 & * & * & * \\\\\n0 & 0 & 0 & 0 & 0 & 0 & \\alpha \\\\\n\\bullet & \\bullet & \\bullet & \\bullet & \\bullet & \\bullet & \\bullet \\\\\n\\bullet & \\bullet & \\bullet & \\bullet & \\bullet & \\bullet & \\bullet\n\\end{array}\n\\right) \\longleftarrow \\alpha \\neq 0\n\\]\nthe \\(i^{\\text {th }}\\) equation of the associated system is\n\\[\n0 x_{1}+0 x_{2}+\\cdots+0 x_{n}=\\alpha .\n\\]\nIf \\(\\alpha\\ne 0\\), this has no solution!\nThis is an inconsistent system.\n\nNote that there is not inconsistency if there is a row of all zeros."
  },
  {
    "objectID": "lectures/ch1_lecture2.html#what-reduced-row-echelon-form-tells-us",
    "href": "lectures/ch1_lecture2.html#what-reduced-row-echelon-form-tells-us",
    "title": "More Systems of Linear Equations",
    "section": "What Reduced Row Echelon Form tells us",
    "text": "What Reduced Row Echelon Form tells us\nSuppose a matrix \\(A_{m \\times n}\\) has a reduced row echelon form \\(E_{m \\times n}\\): \\[ E_A=\\left(\\begin{array}{cccccccc}1 & * & 0 & 0 & * & * & 0 & * \\\\ 0 & 0 & 1 & 0 & * & * & 0 & * \\\\ 0 & 0 & 0 & 1 & * & * & 0 & * \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 1 & * \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\end{array}\\right)\\]\n\nWhat can we learn from the RREF of a matrix? What does it tell us? It can tell us which variables are free vs bound, and therefore how many variables are bound. (This is the rank of the matrix!)"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#which-variables-are-free-and-bound",
    "href": "lectures/ch1_lecture2.html#which-variables-are-free-and-bound",
    "title": "More Systems of Linear Equations",
    "section": "Which variables are free and bound",
    "text": "Which variables are free and bound\nSuppose a matrix \\(A_{m \\times n}\\) has a reduced row echelon form \\(E_{m \\times n}\\): \\[ E_A=\\left(\\begin{array}{cccccccc}1 & * & 0 & 0 & * & * & 0 & * \\\\ 0 & 0 & 1 & 0 & * & * & 0 & * \\\\ 0 & 0 & 0 & 1 & * & * & 0 & * \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 1 & * \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\end{array}\\right)\\]\n“Basic columns” correspond to the columns in \\(A\\) which contain the pivotal positions.\nEach non-basic column can be formed as a sum of the basic columns to the left.\nBasic columns are the same in \\(E\\) and \\(A\\)!"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#rank",
    "href": "lectures/ch1_lecture2.html#rank",
    "title": "More Systems of Linear Equations",
    "section": "Rank",
    "text": "Rank\nSuppose a matrix \\(A_{m \\times n}\\) has a reduced row echelon form \\(E_{m \\times n}\\): \\[ E_A=\\left(\\begin{array}{cccccccc}1 & * & 0 & 0 & * & * & 0 & * \\\\ 0 & 0 & 1 & 0 & * & * & 0 & * \\\\ 0 & 0 & 0 & 1 & * & * & 0 & * \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 1 & * \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\end{array}\\right)\\]\nrank(\\(A\\)) = # of pivots = # of nonzero rows in \\(E\\) = # bound variables in the system"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#nullity",
    "href": "lectures/ch1_lecture2.html#nullity",
    "title": "More Systems of Linear Equations",
    "section": "Nullity",
    "text": "Nullity\nSuppose a matrix \\(A_{m \\times n}\\) has a reduced row echelon form \\(E_{m \\times n}\\): \\[ E_A=\\left(\\begin{array}{cccccccc}1 & * & 0 & 0 & * & * & 0 & * \\\\ 0 & 0 & 1 & 0 & * & * & 0 & * \\\\ 0 & 0 & 0 & 1 & * & * & 0 & * \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 1 & * \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\end{array}\\right)\\]\nnullity(\\(A\\)) = # of non-pivot columns = # free variables in the system"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#consistency-1",
    "href": "lectures/ch1_lecture2.html#consistency-1",
    "title": "More Systems of Linear Equations",
    "section": "Consistency",
    "text": "Consistency\nEquivalent ways of saying \\(A\\) is consistent:\n\nIn row reducing \\([\\mathbf{A} \\mid \\mathbf{b}]\\), a row of the following form never appears:\n\n. . . \\[\n\\left(\\begin{array}{llll|l}\n0 & 0 & \\cdots & 0 & \\alpha \\tag{2.3.2}\n\\end{array}\\right) \\text {, where } \\alpha \\neq 0 \\text {. }\n\\]\n\n\\(\\operatorname{rank}[\\mathbf{A} \\mid \\mathbf{b}]=\\operatorname{rank}(\\mathbf{A})\\), in which case either:\n\n\\(\\operatorname{rank}[\\mathbf{A}=n\\), and system has a unique solution or\n\\(\\operatorname{rank}[\\mathbf{A}&lt;n\\), and system has infinite solutions\n\n\\(\\mathbf{b}\\) is a nonbasic column in \\([\\mathbf{A} \\mid \\mathbf{b}]\\).\n\\(\\mathbf{b}\\) is a combination of the basic columns in \\(\\mathbf{A}\\).\n\n\n\nMeyers p. 51"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#homogeneous-systems",
    "href": "lectures/ch1_lecture2.html#homogeneous-systems",
    "title": "More Systems of Linear Equations",
    "section": "Homogeneous Systems",
    "text": "Homogeneous Systems\n\nThe general linear system with \\(m \\times n\\) coefficient matrix \\(A\\) and right-hand-side vector \\(\\mathbf{b}\\) is homogeneous if the entries of \\(\\mathbf{b}\\) are all zero.\nOtherwise, the system is inhomogeneous.\nHomogeneous systems are always consistent!\nCan solve by setting all variables to zero. This is the trivial solution\nIf rank of the matrix = n, there is only the trivial solution"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#pagerank",
    "href": "lectures/ch1_lecture2.html#pagerank",
    "title": "More Systems of Linear Equations",
    "section": "Pagerank",
    "text": "Pagerank\nGoal: rank pages in terms of “importance”. Suppose we have four pages:\n\n\n\n\nHow can we rank these pages? Which one is most important?\n\n\n\n\nFirst try: count number of backlinks. But that can be artifically inflated (just link to a page many times), and it doesn’t care about importance of the linking page.\nSecond try: For page \\(i\\) let \\(x_{i}\\) be its score and \\(L_{i}\\) be the set of all indices of pages linking to it. Then \\[\n\\begin{equation*}\nx_{i}=\\sum_{x_{j} \\in L_{i}} x_{j}\n\\end{equation*}\n\\]\nBut it’s still easy to game this system, by setting up a page and making a ton of outgoing links to pages we want to promote.\nThird try: For page \\(j\\) let \\(n_{j}\\) be its total number of outgoing links on that page. Then score is\n\\[\n\\begin{equation*}\nx_{i}=\\sum_{x_{j} \\in L_{i}} \\frac{x_{j}}{n_{j}}\n\\end{equation*}\n\\]"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#working-through-pagerank-try-3",
    "href": "lectures/ch1_lecture2.html#working-through-pagerank-try-3",
    "title": "More Systems of Linear Equations",
    "section": "Working through PageRank: try 3",
    "text": "Working through PageRank: try 3\n\n\\[\n\\begin{equation*}\nx_{i}=\\sum_{x_{j} \\in L_{i}} \\frac{x_{j}}{n_{j}}\n\\end{equation*}\n\\]\n\n\n\nWrite down the system of equations this gives us. Then make it in an augmented matrix.\n\n\n\n\n\\[\n\\begin{aligned}\n& x_{1}=\\frac{x_{2}}{1}+\\frac{x_{3}}{3} \\\\\n& x_{2}=\\frac{x_{1}}{2}+\\frac{x_{3}}{3} \\\\\n& x_{3}=\\frac{x_{1}}{2}+\\frac{x_{4}}{1} \\\\\n& x_{4}=\\frac{x_{3}}{3} .\n\\end{aligned}\n\\]\nAugmented matrix:\n\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & -1 & -1 & 0 & 0\\\\-1 & 1 & -1 & 0 & 0\\\\-1 & 0 & 1 & -1 & 0\\\\0 & 0 & -1 & 1 & 0\\end{matrix}\\right]\\)"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#jupyterlab",
    "href": "lectures/ch1_lecture2.html#jupyterlab",
    "title": "More Systems of Linear Equations",
    "section": "JupyterLab",
    "text": "JupyterLab\nhttps://tinyurl.com/stat24320notebook1"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#now-what-about-the-second-try",
    "href": "lectures/ch1_lecture2.html#now-what-about-the-second-try",
    "title": "More Systems of Linear Equations",
    "section": "Now what about the second try?",
    "text": "Now what about the second try?\nRemember this was our ‘second try’: \\[\n\\begin{equation*}\nx_{i}=\\sum_{x_{j} \\in L_{i}} x_{j}\n\\end{equation*}\n\\]\nThis was the system of equations. \\[\n\\begin{aligned}\n& x_{1}=x_{2}+x_{3} \\\\\n& x_{2}=x_{1}+x_{3} \\\\\n& x_{3}=x_{1}+x_{4} \\\\\n& x_{4}=x_{3} .\n\\end{aligned}\n\\]\nWhat happens if we try to solve this? Try it in Python.\n\nWhat happens is that we get only the trivial solution. This makes sense because it is a homogeneous system with full rank."
  },
  {
    "objectID": "lectures/ch1_lecture2.html#discretizing-continuous-functions",
    "href": "lectures/ch1_lecture2.html#discretizing-continuous-functions",
    "title": "More Systems of Linear Equations",
    "section": "Discretizing continuous functions",
    "text": "Discretizing continuous functions\n\nRod with fixed temperatures \\(y_{left}\\) and \\(y_{right}\\) at each end, internal heat source given as \\(f(x), 0 \\leq x \\leq 1\\)\nWhat’s the temperature at each point along the length?"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#section-1",
    "href": "lectures/ch1_lecture2.html#section-1",
    "title": "More Systems of Linear Equations",
    "section": "",
    "text": "Discrete approximation to temperature function \\((n=5)\\)\n\n\n\n\n\nequally spaced points, called nodes, \\(x_{0}=0, x_{1}, x_{2}, \\ldots, x_{n+1}=1\\), distance \\(h\\) apart.\nheat on the \\(i\\) th segment \\(\\approx\\) temperature at its left node.\ntemperature is \\(y(x)\\), \\(y_{i}=y\\left(x_{i}\\right)\\).\n\n\n\n\nEquations to balance the flow of heat from each node to its neighbors:\n\\[\n\\begin{equation*}\n-y_{i-1}+2 y_{i}-y_{i+1}=\\frac{h^{2}}{K} f\\left(x_{i}\\right)\n\\end{equation*}\n\\]"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#section-2",
    "href": "lectures/ch1_lecture2.html#section-2",
    "title": "More Systems of Linear Equations",
    "section": "",
    "text": "Build the matrix representing the system of equations:\n\nN=6\nM = sym.zeros(N)\nfor i in range(N):\n  if (i&gt;0):\n      M[i-1,i]=-1\n  M[i,i]=2\n  if (i&lt;N-1):\n      M[i+1,i]=-1\nM\n\n\\(\\displaystyle \\left[\\begin{matrix}2 & -1 & 0 & 0 & 0 & 0\\\\-1 & 2 & -1 & 0 & 0 & 0\\\\0 & -1 & 2 & -1 & 0 & 0\\\\0 & 0 & -1 & 2 & -1 & 0\\\\0 & 0 & 0 & -1 & 2 & -1\\\\0 & 0 & 0 & 0 & -1 & 2\\end{matrix}\\right]\\)"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#section-3",
    "href": "lectures/ch1_lecture2.html#section-3",
    "title": "More Systems of Linear Equations",
    "section": "",
    "text": "\\[\n\\begin{equation*}\n-y_{i-1}+2 y_{i}-y_{i+1}=\\frac{h^{2}}{K} f\\left(x_{i}\\right)\n\\end{equation*}\n\\]\nDecide on a function for f. Let’s say \\(\\frac{h^{2}}{K} f = x_i^2\\).\nSay that x is running from 0 to 1. Then we can have\n\nimport numpy as np\nx=np.arange(0,1,1/N)\nf=x**2\nx=sym.Matrix(x)\nf=sym.Matrix(f)"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#section-4",
    "href": "lectures/ch1_lecture2.html#section-4",
    "title": "More Systems of Linear Equations",
    "section": "",
    "text": "sol=M.gauss_jordan_solve(f)\nsol[0]\n\n\\(\\displaystyle \\left[\\begin{matrix}0.416666666666667\\\\0.833333333333333\\\\1.22222222222222\\\\1.5\\\\1.52777777777778\\\\1.11111111111111\\end{matrix}\\right]\\)"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#now-you",
    "href": "lectures/ch1_lecture2.html#now-you",
    "title": "More Systems of Linear Equations",
    "section": "Now you",
    "text": "Now you\n\nImplement this yourself in Python\nMake a plot of the output (you’ll want to use PyPlot)\nIncrease N and make more plots\nThis was assuming the temperature at the ends was 0. How can we change this?"
  },
  {
    "objectID": "lectures/ch1_lecture2.html#turing-pattern-formation",
    "href": "lectures/ch1_lecture2.html#turing-pattern-formation",
    "title": "More Systems of Linear Equations",
    "section": "Turing pattern formation",
    "text": "Turing pattern formation\nhttps://colab.research.google.com/github/ijmbarr/turing-patterns/blob/master/turing-patterns.ipynb#scrollTo=GsEPBsz33E14\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n\nDiscrete approximation to temperature function \\((n=5)\\)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stat 24320",
    "section": "",
    "text": "Title\n\n\nLecture Day\n\n\nReadings\n\n\nColab\n\n\n\n\n\n\nIntro to linear systems\n\n\n1\n\n\nCh. 1.1-1.3\n\n\n  \n\n\n\n\nMore Systems of Linear Equations\n\n\n2\n\n\nCh. 1.4-1.5\n\n\n  \n\n\n\n\nCh2 Lecture 1\n\n\n3\n\n\n2.1-2.3\n\n\n \n\n\n\n\nTesting Lightbox\n\n\n3\n\n\n2.1-2.3\n\n\n \n\n\n\n\nCh2 Lecture 2\n\n\n4\n\n\n2.3-2.4\n\n\n \n\n\n\n\na test\n\n\n \n\n\n \n\n\n \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#lecture-notes",
    "href": "index.html#lecture-notes",
    "title": "Stat 24320",
    "section": "",
    "text": "Title\n\n\nLecture Day\n\n\nReadings\n\n\nColab\n\n\n\n\n\n\nIntro to linear systems\n\n\n1\n\n\nCh. 1.1-1.3\n\n\n  \n\n\n\n\nMore Systems of Linear Equations\n\n\n2\n\n\nCh. 1.4-1.5\n\n\n  \n\n\n\n\nCh2 Lecture 1\n\n\n3\n\n\n2.1-2.3\n\n\n \n\n\n\n\nTesting Lightbox\n\n\n3\n\n\n2.1-2.3\n\n\n \n\n\n\n\nCh2 Lecture 2\n\n\n4\n\n\n2.3-2.4\n\n\n \n\n\n\n\na test\n\n\n \n\n\n \n\n\n \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#notebooks",
    "href": "index.html#notebooks",
    "title": "Stat 24320",
    "section": "Notebooks",
    "text": "Notebooks\n\n\n\n\n\nTitle\n\n\nColab\n\n\n\n\n\n\nPageRank Tutorial\n\n\n \n\n\n\n\nTuring Patterns\n\n\n  \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#homeworks",
    "href": "index.html#homeworks",
    "title": "Stat 24320",
    "section": "Homeworks",
    "text": "Homeworks\n\n\n\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nHomework 1\n\n\n \n\n\n\n\nProjects 1 (Not Ready Yet)\n\n\n \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "HW/projects1.html",
    "href": "HW/projects1.html",
    "title": "Projects 1 (Not Ready Yet)",
    "section": "",
    "text": "(Shores 62)\nProblem Description: You are given a long tube of still dry air in which there are 7 sampling/insertion points equally spaced \\(1 / 6\\) meters apart from each other. The position of each point is measured by setting the leftmost point at 0.0 meters and rightmost at 1.0 meters. Initially, a small amount of a certain gas is inserted in the central insertion point. Subsequently, measurements of the concentration of the gas at each sampling/insertion point are taken at later times in seconds. The results of these measurements, which you may assume are accurate to about 2-3 digits, are specified in Table 1.1. Based on this information, your task is to determine the best estimate you can find for the true value of the diffusion coefficient \\(D\\) of this gas in a motionless air medium. Use this estimate and a marching method to calculate values of the material density function on the interval \\([0,1]\\) at times \\(t=210\\) and \\(t=300\\) and at the given spatial nodes.\nProcedure: You should use equation (1.10) or some variant to move backward and forward in time. These will result in linear systems, which ALAMA calculator or another technology tool can solve. One way to proceed is simply to use trial and error until you think you’ve hit on a reasonable value of \\(D\\), that is, the one that gives the best approximation to \\(t=180\\) from the \\(t=360\\)\nTable 1.1: Concentration data measurements of a gaseous material.\nvalues. Do not expect perfect matches - the data is relatively sparse. Then march backwards in time once more to get the initial values at \\(t=0\\). Finally, march forward in time to compute and plot the resulting approximate density function.\nOutput: Discus your results and provide a graph of profiles of the material density function at times in the data table along with your computed profiles.\nComments: This project introduces you to a very interesting area of mathematics called “inverse theory.” The idea is, rather than proceeding from problem (the governing equations for concentration values) to solution (concentration profiles), you are given the “solution,” namely the measured solution values at various points, and are to determine from this information the “problem,” i.e., the diffusion coefficient needed to define the governing equations."
  },
  {
    "objectID": "HW/projects1.html#project-1",
    "href": "HW/projects1.html#project-1",
    "title": "Projects 1 (Not Ready Yet)",
    "section": "",
    "text": "(Shores 62)\nProblem Description: You are given a long tube of still dry air in which there are 7 sampling/insertion points equally spaced \\(1 / 6\\) meters apart from each other. The position of each point is measured by setting the leftmost point at 0.0 meters and rightmost at 1.0 meters. Initially, a small amount of a certain gas is inserted in the central insertion point. Subsequently, measurements of the concentration of the gas at each sampling/insertion point are taken at later times in seconds. The results of these measurements, which you may assume are accurate to about 2-3 digits, are specified in Table 1.1. Based on this information, your task is to determine the best estimate you can find for the true value of the diffusion coefficient \\(D\\) of this gas in a motionless air medium. Use this estimate and a marching method to calculate values of the material density function on the interval \\([0,1]\\) at times \\(t=210\\) and \\(t=300\\) and at the given spatial nodes.\nProcedure: You should use equation (1.10) or some variant to move backward and forward in time. These will result in linear systems, which ALAMA calculator or another technology tool can solve. One way to proceed is simply to use trial and error until you think you’ve hit on a reasonable value of \\(D\\), that is, the one that gives the best approximation to \\(t=180\\) from the \\(t=360\\)\nTable 1.1: Concentration data measurements of a gaseous material.\nvalues. Do not expect perfect matches - the data is relatively sparse. Then march backwards in time once more to get the initial values at \\(t=0\\). Finally, march forward in time to compute and plot the resulting approximate density function.\nOutput: Discus your results and provide a graph of profiles of the material density function at times in the data table along with your computed profiles.\nComments: This project introduces you to a very interesting area of mathematics called “inverse theory.” The idea is, rather than proceeding from problem (the governing equations for concentration values) to solution (concentration profiles), you are given the “solution,” namely the measured solution values at various points, and are to determine from this information the “problem,” i.e., the diffusion coefficient needed to define the governing equations."
  },
  {
    "objectID": "HW/projects1.html#project-1-lu-factorization",
    "href": "HW/projects1.html#project-1-lu-factorization",
    "title": "Projects 1 (Not Ready Yet)",
    "section": "Project 1: LU Factorization",
    "text": "Project 1: LU Factorization\n(Shores p. 177) Write a program module that implements Theorem 2.14 using partial pivoting and implicit row exchanges. This means that space is allocated for the \\(n \\times n\\) matrix \\(A=[a[i, j]]\\) and an array of row indices, say indx \\([i]\\). Initially, indx should consist of the integers \\(1,2, \\ldots, n\\). Whenever two rows need to be exchanged, say the first and third, then the indices indx[1] and indx[3] are exchanged. References to array elements throughout the Gaussian elimination process should be indirect: Refer to the \\((1,4)\\) th entry of \\(A\\) as the element \\(a[\\operatorname{indx}[1], 4]\\). This method of reference has the same effect as physically exchanging rows, but without the work. It also has the appealing feature that we can design the algorithm as though no row exchanges have taken place provided we replace the direct reference \\(a[i, j]\\) by the indirect reference \\(a[\\operatorname{indx}[i], j]\\). The module should return the lower/upper matrix in the format of Example 2.70 as well as the permuted array indx \\([i]\\). Effectively, this index array tells the user what the permutation matrix \\(P\\) is.\nUse this module to implement an LU system solver module that uses the \\(\\mathrm{LU}\\) factorization to solve a general linear system. Also write a module that finds the inverse of an \\(n \\times n\\) matrix \\(A\\) by first using the LU factorization module, then making repeated use of the LU system solver to solve \\(A \\mathbf{x}^{(i)}=\\mathbf{e}_{i}\\), where \\(\\mathbf{e}_{i}\\) is the \\(i\\) th column of the identity. Then we will have\n\\[\nA^{-1}=\\left[\\mathbf{x}^{(1)}, \\mathbf{x}^{(2)}, \\ldots, \\mathbf{x}^{(n)}\\right]\n\\]\nBe sure to document and test your code and report on the results."
  },
  {
    "objectID": "HW/projects1.html#project-2-markov-chains",
    "href": "HW/projects1.html#project-2-markov-chains",
    "title": "Projects 1 (Not Ready Yet)",
    "section": "Project 2: Markov Chains",
    "text": "Project 2: Markov Chains\n(Shores p. 177)\nRefer to Example 2.19 and Section 2.3 for background. Three automobile insurance firms compete for a fixed market of customers. Annual premiums are sold to these customers. Label the companies A, B, and C. You work for Company A, and your team of market analysts has done a survey that draws the following conclusions: In each of the past three years, the number of A customers switching to B is \\(20 \\%\\), and to \\(\\mathrm{C}\\) is \\(30 \\%\\). The number of \\(\\mathrm{B}\\) customers switching to \\(\\mathrm{A}\\) is \\(20 \\%\\), and to \\(\\mathrm{C}\\) is \\(20 \\%\\). The number of \\(\\mathrm{C}\\) customers switching to \\(\\mathrm{A}\\) is \\(30 \\%\\), and to \\(\\mathrm{B}\\) is \\(10 \\%\\). Those who do not switch continue to use their current company’s insurance for the next year. Model this market as a Markov chain. Display the transition matrix for the model. Illustrate the workings of the model by showing what it would predict as the market shares three years from now if currently \\(\\mathrm{A}, \\mathrm{B}\\), and \\(\\mathrm{C}\\) owned equal shares of the market.\nThe next part of your problem is as follows: Your team has tested two advertising campaigns in some smaller test markets and are confident that the first campaign will convince \\(20 \\%\\) of the B customers who would otherwise stay with B in a given year to switch to A. The second advertising campaign would convince \\(20 \\%\\) of the \\(\\mathrm{C}\\) customers who would otherwise stay with C in a given year to switch to A. Both campaigns have about equal costs and would not change other customers’ habits. Make a recommendation, based on your experiments with various possible initial state vectors for the market. Will these campaigns actually improve your company’s market share? If so, which one do you recommend? Write up your recommendation in the form of a report, with supporting evidence. It’s a good idea to hedge on your bets a little by pointing out limitations to your model and claims, so devote a few sentences to those points.\nIt would be a plus to carry the analysis further (your manager might appreciate that). For instance, you could turn the additional market share from, say B customers, into a variable and plot the long-term gain for your company against this variable. A manager could use this data to decide whether it was worthwhile to attempt gaining more customers from B."
  },
  {
    "objectID": "HW/projects1.html#project-3-sports-ranking",
    "href": "HW/projects1.html#project-3-sports-ranking",
    "title": "Projects 1 (Not Ready Yet)",
    "section": "Project 3 Sports Ranking",
    "text": "Project 3 Sports Ranking\n(Shores p. 180)\nRefer to Example 2.24 and Section 2.3 for background. As a sports analyst you are given the following data about a league of seven teams numbered 1-7, where the pair \\((j, k)\\) represents a game in which team \\(j\\) defeated team \\(k\\) :\n\\[\n\\begin{aligned}\nE= & \\{(1,2),(7,3),(2,4),(4,5),(3,2),(5,1),(6,1),(3,1),(7,2),(2,6), \\\\\n& (3,4),(7,4),(5,7),(6,4),(3,5),(5,6),(7,1),(5,2),(7,6),(1,4),(6,3)\\}\n\\end{aligned}\n\\]\nBased on these data you are to rank the teams. To this end, begin with the simplest method, ranking by win/loss record. Next, treat the data as defining a digraph. Begin this analysis by constructing the adjacency matrix of this digraph and drawing a picture of the digraph either by hand or using some software. Then rank the teams by using the following methods: First use the method of Example 2.26 to find a power ranking of each team. Then use the reverse PageRank idea of Example 2.47 to rank the the teams.\nNext, suppose you are given additional information, namely, the game margins (winning score minus losing score) for each game. Following is a list of these margins matching the order of matches in the definition of \\(E\\) :\n\\[\nM=\\{4,8,7,3,7,7,23,15,6,18,13,14,7,13,7,18,45,10,19,14,13\\}\n\\]\nIn order to utilize these data examine your picture of the digraph and label each edge with the margin that matches it in \\(M\\). You are now dealing with a weighted graph and one can construct a different sort of “adjacency matrix” by entering this margin in the \\((i, j)\\) th entry according as team \\(i\\) defeated team \\(j\\) by that margin. Use this approach to calculate “power ranking”."
  },
  {
    "objectID": "HW/projects1.html#project-4",
    "href": "HW/projects1.html#project-4",
    "title": "Projects 1 (Not Ready Yet)",
    "section": "Project 4",
    "text": "Project 4\nProject Descriptions: These projects introduce more applications of digraphs as mathematical modeling tools. You are given that the digraph \\(G\\) has vertex set \\(V=\\{1,2,3,4,5,6\\}\\) and edge set\n\\[\nE=\\{(1,2),(2,3),(3,4),(4,2),(1,4),(3,1),(3,6),(6,3),(4,5),(5,6)\\}\n\\]\nAddress the following points regarding \\(G\\).\n\n\nDraw a picture of this digraph. You may leave space in your report and draw this by hand, or if you prefer, you may use the computer drawing applications available to you on your system.\n\n\n\nExhibit the incidence matrix \\(A\\) of this digraph and find a basis for \\(\\mathcal{N}(A)\\) using its reduced row echelon form. Some of the basis elements may be algebraic but not directed loops. Use this basis to find a basis of directed loops (e.g., non-directed basis element \\(\\mathbf{c}_{1}\\) might be replaced by directed \\(\\mathbf{c}_{1}+\\mathbf{c}_{2}\\) ).\n\n\nThink of the digraph as representing an electrical circuit where an edge represents some electrical object like a resistor or capacitor. Each node represents the circuit space between these objects. and we can attach a potential value to each node, say the potentials are \\(x_{1}, \\ldots, x_{6}\\). The potential difference across an edge is the potential value of head minus tail. Kirchhoff’s second law of electrical circuits says that the sum of potential differences around a circuit loop must be zero. Assume and use the fact (p. 422) that \\(A \\mathbf{x}=\\mathbf{b}\\) implies that for all \\(\\mathbf{y} \\in \\mathcal{N}\\left(A^{T}\\right), \\mathbf{y}^{T} \\mathbf{b}=0\\) to find conditions that a vector \\(\\mathbf{b}\\) must satisfy in order for it to be a vector of potential differences for some potential distribution on the vertices."
  },
  {
    "objectID": "HW/projects1.html#project-5",
    "href": "HW/projects1.html#project-5",
    "title": "Projects 1 (Not Ready Yet)",
    "section": "Project 5",
    "text": "Project 5\n\nAssume that across each edge of a circuit a current flows. Thus, we can assign to each edge a “weight,” namely the current flow along the edge. This is an example of a weighted digraph. However, not just any set of current weights will do, since Kirchhoff’s first law of circuits says that the total flow of current in and out of any node should be 0 . Use this law to find a matrix condition that must be satisfied by the currents and solve it to exhibit some current flows.\nThink of the digraph as representing a directed communications network. Here loops determine which nodes have bidirectional communication since any two nodes of a loop can only communicate with each other by way of a loop. By examining only a basis of directed loops how could you determine which nodes in the network can communicate with each other?"
  },
  {
    "objectID": "HW/projects1.html#project-6",
    "href": "HW/projects1.html#project-6",
    "title": "Projects 1 (Not Ready Yet)",
    "section": "Project 6",
    "text": "Project 6\n\nThink of vertices of the digraph as representing airports and edges representing flight connections between airports for Gamma Airlines. Suppose further that for each connection there is a maximum number of daily flights that will be allowed by the destination airport from an origin airport and that, in the order that the edges in \\(E\\) are listed above, these limits are\n\n\\[\nM=\\{4,3,8,7,2,6,7,10,5,8\\} .\n\\]\nNow suppose that Gamma wants to maximize the flow of flights into airport 1 and out of airport 6 . Count inflows into an airport as positive and outflows as negative. Assume that the net in/outflow of Gamma flights at each airport 1 to 5 is zero, while the net inflow of such flights into airport 1 matches the net outflow from 6 .\n\nDescribe the problem of maximizing this inflow to airport 1 as a linear programming problem and express it in a standard form (block matrices are helpful.) Note that the appropriate variables are all outflows from one airport to another, i.e., along edges, together with the net inflow into airport 1.\nSolve the problem of part (a). Also solve the reverse problem: Maximize inflow into airport 6 and matching outflow from 1. Explain and justify your answers.\n\n\nWith the same limits on allowable flights into airports as in item 5, suppose that Gamma Airlines wants to determine an allocation of planes that will maximize their profits, given the following constraints: (1) Airports 1 and 6 have repair facilities for their planes, so no limit is placed on the inflow or outflow of their planes other than the airport limits. (2) Flights through airports 2-5 of Gamma planes are pass through, i.e., inflow and outflow must match. (3) Gamma has 32 planes available for this network of airports. (4) The profits per flight in thousands are, in the order that the edges in \\(E\\) are listed above,\n\n\\[\nP=\\{5,6,7,9,10,8,9,5,6,10\\}\n\\] (a) Set this problem up as a linear programming problem in standard form. Clearly identify the variables and explain how the constraints follow.\n\nSolve this problem explicitly and specify the operations taken to do so. Example 3.56 is instructive for this problem, so be aware of it. Use a technology tool that allows you to use elementary operations (ALAMA calculator has this capability)."
  },
  {
    "objectID": "HW/HW1.html",
    "href": "HW/HW1.html",
    "title": "Homework 1",
    "section": "",
    "text": "1 \n(Meyer 1.2.10)\nBy solving a \\(3 \\times 3\\) system, find the coefficients in the equation of the parabola \\(y=\\alpha+\\beta x+\\gamma x^{2}\\) that passes through the points \\((1,1),(2,2)\\), and \\((3,0)\\). :::\n\n\n2 \n(Meyer 1.2.11) Suppose that 100 insects are distributed in an enclosure consisting of four chambers with passageways between them as shown below.\n\nAt the end of one minute, the insects have redistributed themselves. Assume that a minute is not enough time for an insect to visit more than one chamber and that at the end of a minute \\(40 \\%\\) of the insects in each chamber have not left the chamber they occupied at the beginning of the minute. The insects that leave a chamber disperse uniformly among the chambers that are directly accessible from the one they initially occupied-e.g., from \\(\\# 3\\), half move to \\(\\# 2\\) and half move to \\(\\# 4\\).\n\nIf at the end of one minute there are \\(12,25,26\\), and 37 insects in chambers \\(\\# 1, \\# 2, \\# 3\\), and \\(\\# 4\\), respectively, determine what the initial distribution had to be.\nIf the initial distribution is \\(20,20,20,40\\), what is the distribution at the end of one minute?\n\n\n\n3 \n(Meyer 1.2.13) Suppose that \\([\\mathbf{A} \\mid \\mathbf{b}]\\) is the augmented matrix associated with a linear system. You know that performing row operations on \\([\\mathbf{A} \\mid \\mathbf{b}]\\) does not change the solution of the system. However, no mention of column operations was ever made because column operations can alter the solution.\n\nDescribe the effect on the solution of a linear system when columns \\(\\mathbf{A}_{* j}\\) and \\(\\mathbf{A}_{* k}\\) are interchanged.\nDescribe the effect when column \\(\\mathbf{A}_{* j}\\) is replaced by \\(\\alpha \\mathbf{A}_{* j}\\) for \\(\\alpha \\neq 0\\).\nDescribe the effect when \\(\\mathbf{A}_{* j}\\) is replaced by \\(\\mathbf{A}_{* j}+\\alpha \\mathbf{A}_{* k}\\). Hint: Experiment with a \\(2 \\times 2\\) or \\(3 \\times 3\\) system.\n\n\n\n4 \n(Meyer 1.3.3) Use the Gauss-Jordan method to solve the following three systems at the same time.\n\\[\n\\begin{array}{rr|l|l}\n2 x_{1}-x_{2} & =1 & 0 & 0 \\\\\n-x_{1}+2 x_{2}-x_{3}&=0 & 1 & 0 \\\\\n-x_{2}+x_{3}&=0 & 0 & 1\n\\end{array}\n\\]\n\n\n5 \n(Meyer 1.5.1) Consider the following system:\n\\[\n\\begin{aligned}\n10^{-3} x-y & =1, \\\\\nx+y & =0 .\n\\end{aligned}\n\\]\n\nUse 3-digit arithmetic with no pivoting to solve this system.\nFind a system that is exactly satisfied by your solution from part (a), and note how close this system is to the original system.\nNow use partial pivoting and 3-digit arithmetic to solve the original system.\nFind a system that is exactly satisfied by your solution from part (c), and note how close this system is to the original system.\nUse exact arithmetic to obtain the solution to the original system, and compare the exact solution with the results of parts (a) and (c).\nRound the exact solution to three significant digits, and compare the result with those of parts (a) and (c).\n\n\n\n6 \n(Meyer 1.5.7) Consider the following well-scaled matrix:\n\\[\n\\mathbf{W}_{n}=\\left(\\begin{array}{rrrrrrr}\n1 & 0 & 0 & \\cdots & 0 & 0 & 1 \\\\\n-1 & 1 & 0 & \\cdots & 0 & 0 & 1 \\\\\n-1 & -1 & 1 & \\ddots & 0 & 0 & 1 \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & \\ddots & \\vdots & \\vdots \\\\\n-1 & -1 & -1 & \\ddots & 1 & 0 & 1 \\\\\n-1 & -1 & -1 & \\cdots & -1 & 1 & 1 \\\\\n-1 & -1 & -1 & \\cdots & -1 & -1 & 1\n\\end{array}\\right)\n\\]\n\nReduce \\(\\mathbf{W}_{n}\\) to an upper-triangular form using Gaussian elimination with partial pivoting, and determine the element of maximal magnitude that emerges during the elimination procedure.\n\n\n\n7 \nAnswer True/False and explain your answers: 1. If a linear system is inconsistent, then the rank of the augmented matrix exceeds the number of unknowns. 2. Any homogeneous linear system is consistent. 3. A system of 3 linear equations in 4 unknowns has infinitely many solutions. 4. Every matrix can be reduced to only one matrix in reduced row form. 5. Any homogeneous linear system with more equations than unknowns has a nontrivial solution."
  },
  {
    "objectID": "course_docs/syllabus.html",
    "href": "course_docs/syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "(Subject to change)\n\n\n\n\n\n\n\n\nWeek\nTopics\nReading\n\n\n\n\n1\nLinear Systems of Equations\nCh. 1\n\n\n2\nMatrix math\n1.3-1.4, 2.1-2.3\n\n\n3\nMatrix math, continued\n2.3-2.5\n\n\n4\n** No class on Monday, April 8 ** Factorization\n2.8\n\n\n5\nVector spaces? Least Squares\n3, 4.2\n\n\n6\nComputer graphics, QR factorization\n4.2, 4.4\n\n\n7\nData compression, wavelets, discrete dynamical systems\n4.4, 5.3\n\n\n8\nPCA, SVD\n5.4, 5.6\n\n\n9\nFourier Transform\n6.6"
  },
  {
    "objectID": "course_docs/syllabus.html#textbook",
    "href": "course_docs/syllabus.html#textbook",
    "title": "Syllabus",
    "section": "Textbook:",
    "text": "Textbook:\nOur textbook is Applied Linear Algebra and Matrix Analysis, 2nd Ed, by Thomas Shores. You can download this textbook for free from the Springer website."
  },
  {
    "objectID": "course_docs/syllabus.html#course-components",
    "href": "course_docs/syllabus.html#course-components",
    "title": "Syllabus",
    "section": "Course components:",
    "text": "Course components:\n\nWeekly homework (problem sets)\nThese will be graded with a standard point scale.\n\n\nThree “project packs”.\nFor each pack, you’ll choose 3 of 4 mini projects to complete. Projects are slightly longer and more open-ended than homework problems. Projects will be graded on an ESMU scale. (This stands for Excellent, Meets Expectations, Revision necessary, and Ungradeable.)\nFor each of the first two project packs, you’ll have the chance to revise and resubmit up to two projects, so long as they were initially graded with an M or R. For the third project pack, you won’t be able to revise and resubmit projects (because this will be due at the end of the quarter).\n\n\nFinal exam\nThere will be a final exam during exam week, in two parts. The first part will be similar to the problems in the problem sets. The second part will be a critical analysis of some applications. You’ll have to suggest directions that you might take in an analysis and look for potential weaknesses in a provided analysis. However, if you’ve gotten at least two Es on your project packs, you won’t have to take the final exam.\nWe will not have a midterm exam."
  },
  {
    "objectID": "course_docs/syllabus.html#course-grading",
    "href": "course_docs/syllabus.html#course-grading",
    "title": "Syllabus",
    "section": "Course grading",
    "text": "Course grading\nThe final grade will be determined by the following weights:\n\nProblem sets: 20%\nFirst part of final exam: 15%\nSecond part of final exam: 15% OR skipped.\nProject packs: 50% OR 65% if the second part of the final exam is skipped.\n\n\n\n\n\n\n\nGrading details\n\n\n\n\n\nProject pack grades are calculated as follows. There are 90 points possible in the project packs, 10 for each project that you complete.\nYou’ll get 10 points for an E or M grade, and 5 points for an R grade. You’ll get 0 points for a U grade. If you revise and resubmit, you’ll get the full points for the grade you receive on the resubmission. If you have at least two E’s from the first two project packs, you may choose to skip the second part of the final exam; in this case, the project packs will be worth 65% of the final grade.\nThe grading for the final project pack will be done differently. You’ll still get 10 points for an E or an M. However, if you get an R on one project and an E on another, the E can be used to bring the R up to an M. So if your grades are E, R, M, this would be changed to M, M, M, for full credit. If your grades are M, R, R, you’d get 20/30 points for this project pack. If your grades are E, R, R, this would be changed to M, M, R, and you’d get 25/30 points. If you get an E on one project and a U on another, the E can be used to bring the U up to an R.\n\n\n\n\n\n\n\n\n\nGrading examples\n\n\n\n\n\nLet’s look at two example students.\nStudent A has the following grades going into the final exam: Problem sets: 90% Project Pack 1: E, S, S (after revision) -&gt; 30/30 Project Pack 2: E, E, S (after revision) -&gt; 30/30\nThe student chooses to skip the second part of the final exam.\nHer grade on the first part of the final exam is 80%. Her grades for the third Project Pack are R, E, R. -&gt; 25/30.\nWhen combined, this student’s project pack grades are 85/90, or 94.4%.\nHer final course grade is 94.40.65+90.20+80*.15 = 91.36%.\nStudent B has the following grades going into the final exam: Problem sets: 80% Project Pack 1: E, S, R (after revision) -&gt; 25/30 Project Pack 2: S, R, R (after revision) -&gt; 20/30\nThis student does not have the option to skip the second part of the final exam.\nHer grade on the first part of the final exam is 87%. Her grade on the second part of the final exam is 90%. Her grade on the third project pack is E, R, R, which becomes S, S, R, for 25/30.\nWhen combined, this student’s project pack grades are 70/90, or 77.8%.\nHer final course grade is 77.80.50+80.20+87.15+90.15 = 81.45%."
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#what-are-linear-systems",
    "href": "lectures/ch1_lecture1b.html#what-are-linear-systems",
    "title": "Intro to linear systems",
    "section": "What are linear systems?",
    "text": "What are linear systems?\n\nSet of one or more linear equations involving the same variables.\nEach equation can be be put in form \\(a_1 x_1 + a_2 x_2 + \\dots + a_n x_n+ b = 0\\)\n\n\n\\[\n\\begin{cases}\na_{11} x_1 + a_{12} x_2 +\\dots + a_{1n} x_n = b_1 \\\\\na_{21} x_1 + a_{22} x_2  + \\dots + a_{2n} x_n = b_2 \\\\\n\\vdots\\\\\na_{m1} x_1 + a_{m2} x_2 + \\dots + a_{mn} x_n = b_m,\n\\end{cases}\n\\]"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#example-railroad-cars",
    "href": "lectures/ch1_lecture1b.html#example-railroad-cars",
    "title": "Intro to linear systems",
    "section": "Example: railroad cars",
    "text": "Example: railroad cars\nA chemical manufacturer wants to lease a fleet of 24 railroad tank cars with a combined carrying capacity of 520,000 gallons.\n\nTank cars with three different carrying capacities are available:\n\n8,000 gallons\n16,000 gallons\n24,000 gallons.\n\nHow many of each type of tank car should be leased?\n\n\nCan write this as \\(x \\times 8+y \\times 16 + z \\times 24=520\\) and also \\(x+y+z=24\\). We won’t have a single solution… Two equations, three unknowns."
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#example-traffic-flow.",
    "href": "lectures/ch1_lecture1b.html#example-traffic-flow.",
    "title": "Intro to linear systems",
    "section": "Example: traffic flow.",
    "text": "Example: traffic flow.\n\n\n\n\nNumbers = # of vehicles/hr that enter and leave on that street.\n\\(x_{1}, x_{2}, x_{3}\\), and \\(x_{4}\\): flow of traffic between the four intersections.\n\n\n\nNumber of vehicles entering each intersection should always equal the number leaving. E.g.:\n\n1,500 vehicles enter the intersection of 5th Street and Washington Avenue each hour\n\\(x_{1}+x_{4}\\) vehicles leave this intersection\n\\(\\rightarrow\\) \\(x_{1}+x_{4}=1,500\\)\n\nFind the traffic flow at each of the other three intersections.\nWhat is the # of vehicles that travel from Washington Avenue to Lincoln Avenue on 5th Street?\n\n\n\n\n\\(x_1+x_2=1200\\), and \\(x_2+x_3=1000\\), and \\(x_3+x_4=1300\\)."
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#example-us-population",
    "href": "lectures/ch1_lecture1b.html#example-us-population",
    "title": "Intro to linear systems",
    "section": "Example: US population",
    "text": "Example: US population\n\nThe U.S. population was approximately 75 million in 1900, 150 million in 1950, and 275 million in 2000.\nFind a quadratic equation whose graph passes through the points \\((0,75)\\), \\((50,150)\\), \\((100,275)\\)\n\n\nCall the years \\((0, 50, 100)\\) \\(t_i\\). Call the populations \\((75,150,275)\\) \\(y_i\\).\nThen we have\n\\[\n\\begin{cases}\nc_1 t_1 + c_2 t_1^2 = y_1 \\\\\nc_1 t_2 + c_2 t_2^2 = y_2 \\\\\nc_1 t_3 + c_2 t_3^2 = y_3\n\\end{cases}\n\\]\n\n\nMake the substitutions \\(c_i \\rightarrow x_i\\) and \\(t_i \\rightarrow a_{1i}\\) and \\(t^2_i \\rightarrow a_{2i}\\), then this becomes\n\\[\n\\begin{cases}\nx_1 a_{11} + x_2 a_{21} =a_{11} x_1  + a_{21} x_2  = y_1 \\\\\nx_1 a_{12} + x_2 a_{22} =a_{12} x_1  +a_{22} x_2 = y_2 \\\\\nx_1 a_{13} + x_2 a_{23} = a_{13} x_1  + a_{23} x_2  = y_3\n\\end{cases}\n\\]\nWe see that we now have a standard system of linear equations."
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#goals-for-solving-algorithms",
    "href": "lectures/ch1_lecture1b.html#goals-for-solving-algorithms",
    "title": "Intro to linear systems",
    "section": "Goals for solving algorithms",
    "text": "Goals for solving algorithms\nAn algorithm should be:\n\nfeasible\naccurate\n\nstable\n\nefficient\n\nreusable computations"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#example-very-simple-linear-system",
    "href": "lectures/ch1_lecture1b.html#example-very-simple-linear-system",
    "title": "Intro to linear systems",
    "section": "Example: very simple linear system",
    "text": "Example: very simple linear system\n\\[\n\\begin{gather*}\n2 x-y=1 \\\\\n4x+4y=20 . \\tag{1.5}\n\\end{gather*}\n\\]\n\nWe can solve this by hand: first we might add four times the first row to the second, so that we get (4+8)x + 0y = 24, so that we realize x = \\(2\\), and then we have 4-y=1 so y = 3.\n\n\nMake an augmented matrix to represent the problem:\n\\[\n\\begin{aligned}\n& x \\quad y=r . h . s . \\\\\n& {\\left[\\begin{array}{rrr}\n2 & -1 & 1 \\\\\n4 & 4 & 20\n\\end{array}\\right]}\n\\end{aligned}\n\\]\n\n\nManipulate the augmented matrix to solve the problem…"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#elementary-matrix-operations",
    "href": "lectures/ch1_lecture1b.html#elementary-matrix-operations",
    "title": "Intro to linear systems",
    "section": "Elementary Matrix Operations",
    "text": "Elementary Matrix Operations\nWhen we do these on augmented matrices, the solutions are unchanged…\n\n\\(E_{i j}\\) : Swap: Switch the \\(i\\)th and \\(j\\) th rows of the matrix.\n\\(E_{i}(c)\\) : Scale: Multiply the \\(i\\)th row by the nonzero constant \\(c\\).\n\\(E_{i j}(d)\\) : Add: Add \\(d\\) times the \\(j\\)th row to the \\(i\\)th row."
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#reduced-row-echelon-form",
    "href": "lectures/ch1_lecture1b.html#reduced-row-echelon-form",
    "title": "Intro to linear systems",
    "section": "Reduced Row Echelon Form",
    "text": "Reduced Row Echelon Form\nEvery matrix can be reduced by a sequence of elementary row operations to one and only one reduced row echelon form:\n\nNonzero rows of \\(R\\) precede the zero rows.\nColumn numbers of the leading entries of the nonzero rows, say rows \\(1,2, \\ldots, r\\), form an increasing sequence of numbers \\(c_{1}&lt;c_{2}&lt;\\cdots&lt;c_{r}\\).\nEach leading entry is a 1.\nEach leading entry has only zeros above it."
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#use-elementary-ops-to-get-reduced-row-echelon-form",
    "href": "lectures/ch1_lecture1b.html#use-elementary-ops-to-get-reduced-row-echelon-form",
    "title": "Intro to linear systems",
    "section": "Use elementary ops to get reduced row echelon form",
    "text": "Use elementary ops to get reduced row echelon form"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#g-j-elimination-for-our-toy-system",
    "href": "lectures/ch1_lecture1b.html#g-j-elimination-for-our-toy-system",
    "title": "Intro to linear systems",
    "section": "G-J Elimination for our toy system",
    "text": "G-J Elimination for our toy system\n\\[\n\\left[\\begin{array}{rrr}\n4 & 4 & 20 \\\\\n2 & -1 & 1\n\\end{array}\\right] \\overrightarrow{E_{1}(\\frac{1}{4}}\\left[\\begin{array}{lll}\n1 & 1 & 5 \\\\\n2 & -1 & 1\n\\end{array}\\right] \\overrightarrow{E_{12}(-2)}\\left[\\begin{array}{lll}\n1 & 1 & 5 \\\\\n0 & -3 & -9\n\\end{array}\\right]\n\\]\nand then…\n\n\\[\n\\left[\\begin{array}{rrr}\n1 & 1 & 5 \\\\\n0 & -3 & -9\n\\end{array}\\right] \\overrightarrow{E_{2}(-1 / 3)}\\left[\\begin{array}{lll}\n1 & 1 & 5 \\\\\n0 & 1 & 3\n\\end{array}\\right] \\overrightarrow{E_{12}(-1)}\\left[\\begin{array}{lll}\n1 & 0 & 2 \\\\\n0 & 1 & 3\n\\end{array}\\right] .\n\\]\n\n\nWriting this back as a linear system, we have:\n\\[\n\\begin{gather*}\n2 x-y=1 \\\\\n4 x+4 y=20\n\\end{gather*}  \\Longrightarrow {\\begin{aligned}\n& 1 \\cdot x+0 \\cdot y=2 \\\\\n& 0 \\cdot x+1 \\cdot y=3\n\\end{aligned}}  \\Longrightarrow {\\begin{aligned}x &= 2 \\\\ y &= 3 \\end{aligned}}\n\\]"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#now-you-try-birds-in-a-tree",
    "href": "lectures/ch1_lecture1b.html#now-you-try-birds-in-a-tree",
    "title": "Intro to linear systems",
    "section": "Now you try: birds in a tree",
    "text": "Now you try: birds in a tree\nThere are 2 trees in a garden (tree “A” and “B”) and in both trees are some birds.\nThe birds of tree A say to the birds of tree B that if one of you comes to our tree, then our population will be double yours.\nThen the birds of tree B tell the birds of tree A that if one of you comes here, then our population will be equal to yours.\nHow many birds in each tree?\n(Solve by making an augmented matrix and doing G-J elimination.)\n\nThe answer is 7 birds in tree A and 5 birds in tree B.\n\n\n\nhttps://www.mathsisfun.com/puzzles/birds-in-trees.html"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#example-mining",
    "href": "lectures/ch1_lecture1b.html#example-mining",
    "title": "Intro to linear systems",
    "section": "Example: Mining",
    "text": "Example: Mining\n\nA mine produces silica, iron, and gold\nNeeds Money (in $$), operating time (in hours), and labor (in person-hours).\n\n1 pound of silica needs: $.0055, . 0011 hours of operating time, and .0093 hours of labor.\n1 pound of iron needs: $.095, . 01 operating hours, and .025 labor hours.\n1 pound of gold needs: $ 960, 112 operating hours, and 560 labor hours.\n\n\nMeyer Ch 1.5"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#section",
    "href": "lectures/ch1_lecture1b.html#section",
    "title": "Intro to linear systems",
    "section": "",
    "text": "Suppose that during 600 hours of operation, exactly $ 5000 and 3000 labor-hours are used.\nHow much silica (\\(x\\)), iron (\\(y\\)), and gold (\\(z\\)) were produced?\n\nSet up the linear system whose solution will yield the values for \\(x, y\\), and \\(z\\).\n\n\n\\[\n\\begin{aligned}\n.0055 x + .095 y + 960 z &=  5000 \\quad \\text{(dollars)}\\\\\n.0011 x + .01 y + 112 z &= 600 \\quad \\text{(operating hours)}\\\\\n.0093 x + .025 y + 560 z &= 3000\\quad \\text{(labor hours)}\n\\end{aligned}\n\\]\n\n\nMake the augmented matrix:\n\\[\n\\left[\\begin{array}{@{}ccc|c@{}}\n.0055 & .095 & 960 & 5000 \\\\\n.0011 & .01  & 112 & 600 \\\\\n.0093 & .025 & 560 & 3000\n\\end{array}\\right]\n\\]\n\nDraw the line on the augmented matrix."
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#section-1",
    "href": "lectures/ch1_lecture1b.html#section-1",
    "title": "Intro to linear systems",
    "section": "",
    "text": "We can solve this using Gauss-Jordan elimination."
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#getting-into-row-echelon-form-rounding-after-3-digits",
    "href": "lectures/ch1_lecture1b.html#getting-into-row-echelon-form-rounding-after-3-digits",
    "title": "Intro to linear systems",
    "section": "Getting into row echelon form, rounding after 3 digits",
    "text": "Getting into row echelon form, rounding after 3 digits\n\\[\\left[\\begin{matrix}0.0055 & 0.095 & 960 & 5000\\\\0.0011 & 0.01 & 112 & 600\\\\0.0093 & 0.025 & 560 & 3000\\end{matrix}\\right] \\overrightarrow{E_{12}(\\frac{-1}{5})} \\left[\\begin{matrix}0.0055 & 0.095 & 9.6 \\cdot 10^{2} & 5.0 \\cdot 10^{3}\\\\0 & -0.009 & -80.0 & -4.0 \\cdot 10^{2}\\\\0.0093 & 0.025 & 5.6 \\cdot 10^{2} & 3.0 \\cdot 10^{3}\\end{matrix}\\right]\\]\n\\[\\overrightarrow{E_{13}(\\frac{93}{55})} \\left[\\begin{matrix}0.0055 & 0.095 & 9.6 \\cdot 10^{2} & 5.0 \\cdot 10^{3}\\\\0 & -0.009 & -80.0 & -4.0 \\cdot 10^{2}\\\\0 & -0.14 & -1.1 \\cdot 10^{3} & -5.4 \\cdot 10^{3}\\end{matrix}\\right]\\]\n\\[\\overrightarrow{E_{23}(\\frac{-14}{.9})} \\left[\\begin{matrix}0.0055 & 0.095 & 9.6 \\cdot 10^{2} & 5.0 \\cdot 10^{3}\\\\0 & -0.009 & -80.0 & -4.0 \\cdot 10^{2}\\\\0 & 0 & 1.4 \\cdot 10^{2} & 5.7 \\cdot 10^{2}\\end{matrix}\\right]\\]"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#section-2",
    "href": "lectures/ch1_lecture1b.html#section-2",
    "title": "Intro to linear systems",
    "section": "",
    "text": "This has solutions \\(\\left[\\begin{matrix}5.7 \\cdot 10^{4}\\\\8.9 \\cdot 10^{3}\\\\4.0\\end{matrix}\\right]\\).\n\nHow do these compare to the exact solutions? These are\n\n\n\\(\\displaystyle \\left[\\begin{matrix}56753.6889897841\\\\8626.56072644719\\\\4.02951191827469\\end{matrix}\\right]\\)"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#doing-it-again-rounding-after-15-digits",
    "href": "lectures/ch1_lecture1b.html#doing-it-again-rounding-after-15-digits",
    "title": "Intro to linear systems",
    "section": "Doing it again, rounding after 15 digits",
    "text": "Doing it again, rounding after 15 digits\n\\(\\left[\\begin{matrix}0.0055 & 0.095 & 960 & 5000\\\\0.0011 & 0.01 & 112 & 600\\\\0.0093 & 0.025 & 560 & 3000\\end{matrix}\\right] \\rightarrow \\left[\\begin{matrix}0.0055 & 0.095 & 960.0 & 5000.0\\\\0 & -0.009 & -80.0 & -400.0\\\\0.0093 & 0.025 & 560.0 & 3000.0\\end{matrix}\\right]\\)\n\\(\\rightarrow \\left[\\begin{matrix}0.0055 & 0.095 & 960.0 & 5000.0\\\\0 & -0.009 & -80.0 & -400.0\\\\0 & -0.135636363636364 & -1063.27272727273 & -5454.54545454545\\end{matrix}\\right] \\rightarrow \\left[\\begin{matrix}0.0055 & 0.095 & 960.0 & 5000.0\\\\0 & -0.009 & -80.0 & -400.0\\\\0 & 0 & 142.383838383838 & 573.737373737372\\end{matrix}\\right]\\)\nThis has solutions \\(\\left[\\begin{matrix}56753.6889897845\\\\8626.56072644727\\\\4.02951191827468\\end{matrix}\\right]\\).\nReminder, the exact solution was:\n\n\n\\(\\displaystyle \\left[\\begin{matrix}56753.6889897841\\\\8626.56072644719\\\\4.02951191827469\\end{matrix}\\right]\\)"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#reminder-of-goals",
    "href": "lectures/ch1_lecture1b.html#reminder-of-goals",
    "title": "Intro to linear systems",
    "section": "Reminder of goals",
    "text": "Reminder of goals\nAn algorithm should be:\n\n\nfeasible\naccurate\n\nstable\n\nefficient\n\nreusable computations"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#roundoff-errors-with-g-j-elimination",
    "href": "lectures/ch1_lecture1b.html#roundoff-errors-with-g-j-elimination",
    "title": "Intro to linear systems",
    "section": "Roundoff errors with G-J elimination",
    "text": "Roundoff errors with G-J elimination\nTry this on your calculator. What do you get?\n\\[\n\\left(\\left(\\frac{2}{3}+100\\right)-100\\right)-\\frac{2}{3}\\stackrel{?}{=}0\n\\]\n\nNow try this…\n\\[\n\\left(\\left(\\frac{2}{3}+100\\right)-100\\right)-\\frac{2}{3}\\stackrel{?}{=}0\n\\]\n\nOn my calculator, I get 3.33e-32. That’s a small number, but not zero!\nWhat is happening is that 2/3 = 0.666666…., and your calculator represents this as a very long string but eventually puts in a 7.\nThen when it adds the 100, it has to drop a few of those digits in its representation. They are then gone! When we subtract the 100, we don’t get them back again."
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#section-3",
    "href": "lectures/ch1_lecture1b.html#section-3",
    "title": "Intro to linear systems",
    "section": "",
    "text": "Let \\(\\epsilon\\) be a number so small that our calculator yields \\(1+\\epsilon=1\\).\nWith this calculator, \\(1+1 / \\epsilon=(\\epsilon+1) / \\epsilon=1 / \\epsilon\\)\nWant to solve the linear system\n\\[\n  \\begin{align*}\n  \\epsilon x_{1}+x_{2} & =1\\\\\n  x_{1}-x_{2} & =0 .\n  \\end{align*}\n\\]"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#roundoff-errors-with-g-j-elimination-1",
    "href": "lectures/ch1_lecture1b.html#roundoff-errors-with-g-j-elimination-1",
    "title": "Intro to linear systems",
    "section": "Roundoff errors with G-J elimination",
    "text": "Roundoff errors with G-J elimination\nWith our calculator,\n\nIn the second step, we are replacing \\(-1+\\frac{1}{\\epsilon}\\) with just \\(\\frac{1}{\\epsilon}\\). It’s a case where we are adding together numbers of very different scale.\n\n\\[\n    \\left[\\begin{array}{rrr}\n    \\epsilon & 1 & 1 \\\\\n    1 & -1 & 0\n    \\end{array}\\right] \\overrightarrow{E_{21}\\left(-\\frac{1}{\\epsilon}\\right)}\\left[\\begin{array}{ccc}\n    \\epsilon & 1 & 1 \\\\\n    0 & \\frac{1}{\\epsilon} & -\\frac{1}{\\epsilon}\n    \\end{array}\\right] \\overrightarrow{E_{2}(\\epsilon)}\\left[\\begin{array}{ccc}\n    \\epsilon & 1 & 1 \\\\\n    0 & 1 & 1\n    \\end{array}\\right] \\\\ \\overrightarrow{E_{12}(-1)}\\left[\\begin{array}{ccc}\n    \\epsilon & 0 & 0 \\\\\n    0 & 1 & 1\n    \\end{array}\\right]  \\overrightarrow{E_{1}\\left(\\frac{1}{\\epsilon}\\right)}\\left[\\begin{array}{lll}\n    1 & 0 & 0 \\\\\n    0 & 1 & 1\n    \\end{array}\\right] .\n\\]\n\nCalculated solution: \\(x_{1}=0, x_{2}=1\\)\nCorrect answer should be\n\\[ x_{1}=x_{2}=\\frac{1}{1+\\epsilon}=0.999999099999990 \\ldots\\]"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#sensitivity-to-small-changes",
    "href": "lectures/ch1_lecture1b.html#sensitivity-to-small-changes",
    "title": "Intro to linear systems",
    "section": "Sensitivity to small changes",
    "text": "Sensitivity to small changes\nProblem arose because we took a computational step where we added two numbers of very different scale, essentially losing the smaller number.\nLed to a big changes in output!\nThere is no general cure for these difficulties…\nWant to be aware of them, know when we are doing computations that might be susceptible."
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#partial-pivoting",
    "href": "lectures/ch1_lecture1b.html#partial-pivoting",
    "title": "Intro to linear systems",
    "section": "Partial pivoting",
    "text": "Partial pivoting\nWe can improve performance of G-J by introducing a new step into the algorithm:\n\nFind the entry in the left column with the largest absolute value. This entry is called the pivot. Perform row interchange (if necessary), so that the pivot is in the first row.\nUse a row operation to get a 1 as the entry in the first row and first column.\nUse row operations to make all other entries as zeros in column one.\nInterchange rows if necessary to obtain a nonzero number with the largest absolute value in the second row, second column. Use a row operation to make this entry 1. Use row operations to make all other entries as zeros in column two.\nRepeat step 4 for row 3, column 3. Continue moving along the main diagonal until you reach the last row, or until the number is zero.\n\n\nFull pivoting is where we also move the columns around to get the largest element to the front.\n” A square matrix 𝐴 has an 𝐿𝑈 factorization (without pivoting) if, and only if, no zero is encountered in the pivot position when computing an 𝐿𝑈 factorization of 𝐴. However, when does computations using floating point numbers a pivot that is nearly zero can lead to dramatic rounding errors. The simple workaround is to always permute the rows of the matrix such that the largest nonzero entry in a column is chosen as the pivot entry. This ensures that a nearly zero is never chosen. Complete pivoting goes even further by using row and column permutations to select the largest entry in the entire matrix as the pivot entry.” from here\nIt’s very rare to find yourself in a situation where you need complete pivoting, and sometimes it can be quite computationally expensive."
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#using-partial-pivoting-in-our-example",
    "href": "lectures/ch1_lecture1b.html#using-partial-pivoting-in-our-example",
    "title": "Intro to linear systems",
    "section": "Using partial pivoting in our example",
    "text": "Using partial pivoting in our example\n\nwork this one out by hand"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#ill-conditioned-linear-systems-1",
    "href": "lectures/ch1_lecture1b.html#ill-conditioned-linear-systems-1",
    "title": "Intro to linear systems",
    "section": "Ill-conditioned linear systems",
    "text": "Ill-conditioned linear systems\n\nSometimes it’s not the procedure that introduces the susceptibility to small changes, but the actual problem itself. Then, small differences in the inputs lead to big differences in the exact solutions.\n\n\nA system of linear equations is said to be ill-conditioned when some small perturbation in the system (in the \\(b\\)s) can produce relatively large changes in the exact solution (in the \\(x\\)’s). Otherwise, the system is said to be well-conditioned."
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#ill-conditioned-linear-systems-2",
    "href": "lectures/ch1_lecture1b.html#ill-conditioned-linear-systems-2",
    "title": "Intro to linear systems",
    "section": "Ill-conditioned linear systems",
    "text": "Ill-conditioned linear systems\n\n\n\nConsider \\[\n\\begin{aligned}\n& .835 x+.667 y=.168, \\\\\n& .333 x+.266 y=.067,\n\\end{aligned}\n\\]\nExact solution:\n\\[\nx=1 \\quad \\text { and } \\quad y=-1 .\n\\]\n\n\nBut if we change just one digit…\n\\[\n\\begin{aligned}\n& .835 x+.667 y=.168, \\\\\n& .333 x+.266 y=.06\\color{red}{6},\n\\end{aligned}\n\\]\nNow exact solution:\n\\[\n\\hat{x}=-666 \\quad \\text { and } \\quad \\hat{y}=834\n\\]\n\n\n\n\nWhat’s going on here? One thing to notice is that the lines corresponding to solutions for each equation have very similar slopes: r .667/.835 vs r .266/.33.\n\n\nMeyer Ch 1.6"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#section-4",
    "href": "lectures/ch1_lecture1b.html#section-4",
    "title": "Intro to linear systems",
    "section": "",
    "text": "What if \\(b_1\\) and \\(b_2\\) are the results of an experiment, need to be read off a dial? Suppose:\n\ndial can be read to tolerance of \\(\\pm .001\\),\nvalues for \\(b_{1}\\) and \\(b_{2}\\) are read as .168 and .067, respectively. Then the exact solution is\n\n\n\\[\n\\begin{equation*}\n(x, y)=(1,-1)\n\\end{equation*}\n\\]\n\n\nBut due to uncertainty, we have\n\n\n\\[\n\\begin{equation*}\n.167 \\leq b_{1} \\leq .169 \\quad \\text { and } \\quad .066 \\leq b_{2} \\leq .068\n\\end{equation*}\n\\]"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#section-5",
    "href": "lectures/ch1_lecture1b.html#section-5",
    "title": "Intro to linear systems",
    "section": "",
    "text": "Possible readings\n\n\n\\(b_1\\)\n\\(b_2\\)\n\\(x\\)\n\\(y\\)\n\n\n\n\n.168\n.067\n1\n-1\n\n\n.167\n.068\n934\n-1169\n\n\n.169\n.066\n-932\n1169"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#geometrical-interpretation",
    "href": "lectures/ch1_lecture1b.html#geometrical-interpretation",
    "title": "Intro to linear systems",
    "section": "Geometrical interpretation",
    "text": "Geometrical interpretation\nIf two straight lines are almost parallel and if one of the lines is moved only slightly, then the point of intersection is drastically altered.\n\nThe point of intersection is the solution of the associated \\(2 \\times 2\\) linear system, so this is also drastically altered."
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#section-6",
    "href": "lectures/ch1_lecture1b.html#section-6",
    "title": "Intro to linear systems",
    "section": "",
    "text": "Often in real life, coefficients are empirically obtained\nWill be off from “true” values by small amounts\nFor ill-conditioned systems, this means that solutions can be very far off from true solutions\nWe’ll cover techniques for quantifying conditioning, later in quarter\nFor now, can just try making small changes to some coefficients. Big changes in result? Ill-conditioned system!"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#polynomial-interpolation",
    "href": "lectures/ch1_lecture1b.html#polynomial-interpolation",
    "title": "Intro to linear systems",
    "section": "Polynomial interpolation",
    "text": "Polynomial interpolation\n\nSuppose we’d like to find a polynomial that can interpolate a given function.\nTake points 𝑥0,…𝑥𝑁 and values 𝑦0,…𝑦𝑁\nSimple way: finding the coefficients $ c_1, c_n $ where\n\\[\nP(x) = \\sum_{i=0}^N c_i x^i\n\\]\n\nThis is a system of equations:\n\\[\n\\begin{array}\n    cy_0 = c_0 + c_1 x_0 + \\ldots c_N x_0^N\\\\\n    \\,\\ldots\\\\\n    \\,y_N = c_0 + c_1 x_N + \\ldots c_N x_N^N\n\\end{array}\n\\]\n\n\nhttps://colab.research.google.com/github/quantecon/lecture-julia.notebooks/blob/main/tools_and_techniques/iterative_methods_sparsity.ipynb#scrollTo=9aa1791b"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#polynomial-interpolation-1",
    "href": "lectures/ch1_lecture1b.html#polynomial-interpolation-1",
    "title": "Intro to linear systems",
    "section": "Polynomial interpolation",
    "text": "Polynomial interpolation\nOr, stacking, \\(c = \\begin{bmatrix} c_0 & \\ldots & c_N\\end{bmatrix}\\), \\(y = \\begin{bmatrix} y_0 & \\ldots & y_N\\end{bmatrix}\\) , and\n\\[\nA = \\begin{bmatrix} 1 & x_0 & x_0^2 & \\ldots &x_0^N\\\\\n                    \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n                    1 & x_N & x_N^2 & \\ldots & x_N^N\n    \\end{bmatrix}\n\\]\nLet’s try solving this for a simple function, \\(y=exp(x)\\)."
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#polynomial-interpolation-2",
    "href": "lectures/ch1_lecture1b.html#polynomial-interpolation-2",
    "title": "Intro to linear systems",
    "section": "Polynomial interpolation",
    "text": "Polynomial interpolation\n\\[\nx*y\n\\]\nWe’ll start with picking 4 interpolating points: \\(\\vec x = \\mathtt{\\text{[ 1.          4.66666667  8.33333333 12.        ]}}\\). Then we have our matrix A:\n\\[A = \\begin{bmatrix} 1 & x_0 & x_0^2 & \\ldots &x_0^N\\\\\n                    \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n                    1 & x_N & x_N^2 & \\ldots & x_N^N\n    \\end{bmatrix} = \\left[\\begin{matrix}1.0 & 1.0 & 1.0 & 1.0\\\\1.0 & 4.66666666666667 & 21.7777777777778 & 101.62962962963\\\\1.0 & 8.33333333333333 & 69.4444444444444 & 578.703703703703\\\\1.0 & 12.0 & 144.0 & 1728.0\\end{matrix}\\right] \\]\nOur \\(y\\) values are \\(\\vec y = \\mathtt{\\text{[     2.71828183    106.3426754    4160.26200538 162754.791419  ]}}\\). We could solve this using Gauss-Jordan elimination, or here the solving algorithm built into Numpy."
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#results-for-n4-and-n10-points",
    "href": "lectures/ch1_lecture1b.html#results-for-n4-and-n10-points",
    "title": "Intro to linear systems",
    "section": "Results for n=4 and n=10 points",
    "text": "Results for n=4 and n=10 points"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#max-error-for-different-values-of-n",
    "href": "lectures/ch1_lecture1b.html#max-error-for-different-values-of-n",
    "title": "Intro to linear systems",
    "section": "Max error for different values of n",
    "text": "Max error for different values of n"
  },
  {
    "objectID": "lectures/ch1_lecture1b.html#the-problem-linear-dependency",
    "href": "lectures/ch1_lecture1b.html#the-problem-linear-dependency",
    "title": "Intro to linear systems",
    "section": "The problem: linear dependency",
    "text": "The problem: linear dependency\n\n\n\n\n\n\n\n\n\n\nAs n gets higher, \\(x^n\\) gets closer to \\(x^{n+1}\\) (at least in the range \\((0,1)\\)). This means that a solution of \\(a_n x^n + a_{n+1} x^{n+1}\\) will be very similar to e.g. \\(a_{n+1} x^n + a_{n} x^{n+1}\\)"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#diffusion",
    "href": "lectures/ch2_lecture1.html#diffusion",
    "title": "Ch2 Lecture 1",
    "section": "Diffusion",
    "text": "Diffusion\n\nLast week, we talked about the diffusion equation. Here is the exact form:\n\\[\\frac{\\partial a(x,t)}{\\partial t} = D_{a}\\frac{\\partial^{2} a(x,t)}{\\partial x^{2}}\\]\n\nWalk through why we have a first derivative for time, and a second derivative for space. It’s because if the concentration is increasing steadily in space at a given position, the same amount will enter (from the left) and leave (from the right). We only end up with a changing concentration if the rate of entry and exit are different.\n\n\nWe approximated this using the finite-difference method:\nTime derivative (which we had set to zero):\n\\[\n\\frac{\\partial a(x,t)}{\\partial t} \\approx \\frac{1}{dt}(a_{x,t+1} - a_{x,t})\n\\]\nSpacial part of the derivative (which is usually know as the Laplacian):\n\\[\n\\frac{\\partial^{2} a(x,t)}{\\partial x^{2}} \\approx \\frac{1}{dx^{2}}(a_{x+1,t} + a_{x-1,t} - 2a_{x,t})\n\\]\n\n\nThis gives us the finite-difference equation:\n\\[\na_{x,t+1} = a_{x,t} + dt\\left(  \\frac{D_{a}}{dx^{2}}(a_{x+1,t} + a_{x-1,t} - 2a_{x,t})  \\right)\n\\]\n\n\nAdapted from this blog post."
  },
  {
    "objectID": "lectures/ch2_lecture1.html#boundary-conditions",
    "href": "lectures/ch2_lecture1.html#boundary-conditions",
    "title": "Ch2 Lecture 1",
    "section": "Boundary Conditions",
    "text": "Boundary Conditions\n\nLast week, with our metal rod, we had boundary conditions where the temperatures at the ends of the rod were fixed at 0 degrees.\nWe needed to say something about the boundaries to solve the system of equations.\nAnother option is periodic boundary conditions.\nThese are like imagining the rod is a loop, so the temperature at the end of the rod is the same as the temperature at the beginning of the rod."
  },
  {
    "objectID": "lectures/ch2_lecture1.html#periodic-boundary-conditions-np.roll",
    "href": "lectures/ch2_lecture1.html#periodic-boundary-conditions-np.roll",
    "title": "Ch2 Lecture 1",
    "section": "Periodic Boundary Conditions: np.roll",
    "text": "Periodic Boundary Conditions: np.roll\n\nWant an easy way to compute \\(a_{x+1}\\) for all \\(x\\)’s\nSuppose we have n points, and we want to compute \\(a_{x+1}\\) for all \\(x\\)=n.\nProblem: \\(a_{x+1}\\) would be off the end of the array!\nJust replace \\(a_{n+1}\\) with \\(a_{1}\\)\nCan do this easily with np.roll. Lets us compute \\(a_{x+1}\\) for all \\(x\\)’s.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/ch2_lecture1.html#laplacian-with-periodic-boundary-conditions-in-python",
    "href": "lectures/ch2_lecture1.html#laplacian-with-periodic-boundary-conditions-in-python",
    "title": "Ch2 Lecture 1",
    "section": "Laplacian with Periodic Boundary Conditions in Python",
    "text": "Laplacian with Periodic Boundary Conditions in Python\n\nimport numpy as np\ndef laplacian1D(a, dx):\n    return (\n        - 2 * a\n        + np.roll(a,1,axis=0)\n        + np.roll(a,-1,axis=0)\n    ) / (dx ** 2)\n\ndef laplacian2D(a, dx):\n    return (\n        - 4 * a\n        + np.roll(a,1,axis=0)\n        + np.roll(a,-1,axis=0)\n        + np.roll(a,+1,axis=1)\n        + np.roll(a,-1,axis=1)\n    ) / (dx ** 2)\n\n\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#solving-and-animating",
    "href": "lectures/ch2_lecture1.html#solving-and-animating",
    "title": "Ch2 Lecture 1",
    "section": "Solving and animating",
    "text": "Solving and animating\n\nclass OneDimensionalDiffusionEquation(BaseStateSystem):\n    def __init__(self, D):\n        self.D = D\n        self.width = 1000\n        self.dx = 10 / self.width\n        self.dt = 0.9 * (self.dx ** 2) / (2 * D)\n        self.steps = int(0.1 / self.dt)\n\n    def initialise(self):\n        self.t = 0\n        self.X = np.linspace(-5,5,self.width)\n        self.a = np.exp(-self.X**2)\n\n    def update(self):\n        for _ in range(self.steps):\n            self.t += self.dt\n            self._update()\n\n    def _update(self):\n        La = laplacian1D(self.a, self.dx)\n        delta_a = self.dt * (self.D * La)\n        self.a += delta_a\n\n    def draw(self, ax):\n        ax.clear()\n        ax.plot(self.X,self.a, color=\"r\")\n        ax.set_ylim(0,1)\n        ax.set_xlim(-5,5)\n        ax.set_title(\"t = {:.2f}\".format(self.t))\n\none_d_diffusion = OneDimensionalDiffusionEquation(D=1)\n\none_d_diffusion.plot_time_evolution(\"diffusion.gif\")\n\n\n\n\ndiffusion.gif"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#reaction-terms",
    "href": "lectures/ch2_lecture1.html#reaction-terms",
    "title": "Ch2 Lecture 1",
    "section": "Reaction Terms",
    "text": "Reaction Terms\n\nWe will have a system with two chemical components, \\(a\\) and \\(b\\).\nSuppose \\(a\\) activates genes which produce pigmentation. \\(b\\) inhibits \\(a\\)\nWill start with some random small initial concentrations of \\(a\\) and \\(b\\).\nEach will diffuse according to the diffusion equation.\nThey will also react with each other, changing the concentration of each.\n\n\nFor the reaction equations, will use the FitzHugh–Nagumo equation\n\\(R_a(a, b) = a - a^{3} - b + \\alpha\\)\n\\(R_{b}(a, b) = \\beta (a - b)\\)\nWhere \\(\\alpha\\) and \\(\\beta\\) are constants."
  },
  {
    "objectID": "lectures/ch2_lecture1.html#reaction-equation-evolution-at-one-point-in-space",
    "href": "lectures/ch2_lecture1.html#reaction-equation-evolution-at-one-point-in-space",
    "title": "Ch2 Lecture 1",
    "section": "Reaction Equation evolution at one point in space",
    "text": "Reaction Equation evolution at one point in space\n\nclass ReactionEquation(BaseStateSystem):\n    def __init__(self, Ra, Rb):\n        self.Ra = Ra\n        self.Rb = Rb\n        self.dt = 0.01\n        self.steps = int(0.1 / self.dt)\n\n    def initialise(self):\n        self.t = 0\n        self.a = 0.1\n        self.b = 0.7\n        self.Ya = []\n        self.Yb = []\n        self.X = []\n\n    def update(self):\n        for _ in range(self.steps):\n            self.t += self.dt\n            self._update()\n\n    def _update(self):\n        delta_a = self.dt * self.Ra(self.a,self.b)\n        delta_b = self.dt * self.Rb(self.a,self.b)\n\n        self.a += delta_a\n        self.b += delta_b\n\n    def draw(self, ax):\n        ax.clear()\n\n        self.X.append(self.t)\n        self.Ya.append(self.a)\n        self.Yb.append(self.b)\n\n        ax.plot(self.X,self.Ya, color=\"r\", label=\"A\")\n        ax.plot(self.X,self.Yb, color=\"b\", label=\"B\")\n        ax.legend()\n\n        ax.set_ylim(0,1)\n        ax.set_xlim(0,5)\n        ax.set_xlabel(\"t\")\n        ax.set_ylabel(\"Concentrations\")\n\nalpha, beta =  0.2, 5\n\ndef Ra(a,b): return a - a ** 3 - b + alpha\ndef Rb(a,b): return (a - b) * beta\n\none_d_reaction = ReactionEquation(Ra, Rb)\none_d_reaction.plot_time_evolution(\"reaction.gif\", n_steps=50)"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#section",
    "href": "lectures/ch2_lecture1.html#section",
    "title": "Ch2 Lecture 1",
    "section": "",
    "text": "reaction.gif"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#full-model",
    "href": "lectures/ch2_lecture1.html#full-model",
    "title": "Ch2 Lecture 1",
    "section": "Full Model",
    "text": "Full Model\nWe now have two parts: - a diffusion term that “spreads” out concentration - a reaction part the equalises the two concentrations. . . .\nWhat happens when we put the two together? Do we get something stable?"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#section-1",
    "href": "lectures/ch2_lecture1.html#section-1",
    "title": "Ch2 Lecture 1",
    "section": "",
    "text": "def random_initialiser(shape):\n    return(\n        np.random.normal(loc=0, scale=0.05, size=shape),\n        np.random.normal(loc=0, scale=0.05, size=shape)\n    )\n\nclass OneDimensionalRDEquations(BaseStateSystem):\n    def __init__(self, Da, Db, Ra, Rb,\n                 initialiser=random_initialiser,\n                 width=1000, dx=1,\n                 dt=0.1, steps=1):\n\n        self.Da = Da\n        self.Db = Db\n        self.Ra = Ra\n        self.Rb = Rb\n\n        self.initialiser = initialiser\n        self.width = width\n        self.dx = dx\n        self.dt = dt\n        self.steps = steps\n\n    def initialise(self):\n        self.t = 0\n        self.a, self.b = self.initialiser(self.width)\n\n    def update(self):\n        for _ in range(self.steps):\n            self.t += self.dt\n            self._update()\n\n    def _update(self):\n\n        # unpack so we don't have to keep writing \"self\"\n        a,b,Da,Db,Ra,Rb,dt,dx = (\n            self.a, self.b,\n            self.Da, self.Db,\n            self.Ra, self.Rb,\n            self.dt, self.dx\n        )\n\n        La = laplacian1D(a, dx)\n        Lb = laplacian1D(b, dx)\n\n        delta_a = dt * (Da * La + Ra(a,b))\n        delta_b = dt * (Db * Lb + Rb(a,b))\n\n        self.a += delta_a\n        self.b += delta_b\n\n    def draw(self, ax):\n        ax.clear()\n        ax.plot(self.a, color=\"r\", label=\"A\")\n        ax.plot(self.b, color=\"b\", label=\"B\")\n        ax.legend()\n        ax.set_ylim(-1,1)\n        ax.set_title(\"t = {:.2f}\".format(self.t))\n\nDa, Db, alpha, beta = 1, 100, -0.005, 10\n\ndef Ra(a,b): return a - a ** 3 - b + alpha\ndef Rb(a,b): return (a - b) * beta\n\nwidth = 100\ndx = 1\ndt = 0.001\n\nOneDimensionalRDEquations(\n    Da, Db, Ra, Rb,\n    width=width, dx=dx, dt=dt,\n    steps=100\n).plot_time_evolution(\"1dRD.gif\", n_steps=150)"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#section-2",
    "href": "lectures/ch2_lecture1.html#section-2",
    "title": "Ch2 Lecture 1",
    "section": "",
    "text": "1dRD.gif"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#in-two-dimensions",
    "href": "lectures/ch2_lecture1.html#in-two-dimensions",
    "title": "Ch2 Lecture 1",
    "section": "In two dimensions",
    "text": "In two dimensions\n\n\n\n2dRD.png"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#matrix-addition-and-subtraction",
    "href": "lectures/ch2_lecture1.html#matrix-addition-and-subtraction",
    "title": "Ch2 Lecture 1",
    "section": "Matrix Addition and Subtraction",
    "text": "Matrix Addition and Subtraction\nReview matrix addition and subtraction on your own!"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#matrix-multiplication",
    "href": "lectures/ch2_lecture1.html#matrix-multiplication",
    "title": "Ch2 Lecture 1",
    "section": "Matrix Multiplication",
    "text": "Matrix Multiplication\nFor motivation:\n\\[\n2 x-3 y+4 z=5 \\text {. }\n\\]\n\nCan write as a “product” of the coefficient matrix \\([2,-3,4]\\) and and the column matrix of unknowns \\(\\left[\\begin{array}{l}x \\\\ y \\\\ z\\end{array}\\right]\\).\n\n\nThus, product is:\n\\[\n[2,-3,4]\\left[\\begin{array}{l}\nx \\\\\ny \\\\\nz\n\\end{array}\\right]=[2 x-3 y+4 z]\n\\]"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#definition-of-matrix-product",
    "href": "lectures/ch2_lecture1.html#definition-of-matrix-product",
    "title": "Ch2 Lecture 1",
    "section": "Definition of matrix product",
    "text": "Definition of matrix product\n\\(A=\\left[a_{i j}\\right]\\): \\(m \\times p\\) matrix\n\\(B=\\left[b_{i j}\\right]\\): \\(p \\times n\\) matrix.\nProduct of \\(A\\) and \\(B\\) – \\(A B\\)\n\nis \\(m \\times n\\) matrix whose\n\\((i, j)\\) th entry is the entry of the product of the \\(i\\) th row of \\(A\\) and the \\(j\\) th column of \\(B\\);\n\n\nMore specifically, the \\((i, j)\\) th entry of \\(A B\\) is\n\\[\na_{i 1} b_{1 j}+a_{i 2} b_{2 j}+\\cdots+a_{i p} b_{p j} .\n\\]\nReminder: Matrix Multiplication is not Commutative\n\n\\(A B \\neq B A\\) in general."
  },
  {
    "objectID": "lectures/ch2_lecture1.html#linear-systems-as-a-matrix-product",
    "href": "lectures/ch2_lecture1.html#linear-systems-as-a-matrix-product",
    "title": "Ch2 Lecture 1",
    "section": "Linear Systems as a Matrix Product",
    "text": "Linear Systems as a Matrix Product\nWe can express a linear system of equations as a matrix product:\n\\[\n\\begin{aligned}\nx_{1}+x_{2}+x_{3} & =4 \\\\\n2 x_{1}+2 x_{2}+5 x_{3} & =11 \\\\\n4 x_{1}+6 x_{2}+8 x_{3} & =24\n\\end{aligned}\n\\]\n\n\\[\n\\mathbf{x}=\\left[\\begin{array}{l}\nx_{1} \\\\\nx_{2} \\\\\nx_{3}\n\\end{array}\\right], \\quad \\mathbf{b}=\\left[\\begin{array}{r}\n4 \\\\\n11 \\\\\n24\n\\end{array}\\right], \\quad \\text { and } A=\\left[\\begin{array}{lll}\n1 & 1 & 1 \\\\\n2 & 2 & 5 \\\\\n4 & 6 & 8\n\\end{array}\\right]\n\\]\n\nOf course, \\(A\\) is just the coefficient matrix of the system and \\(b\\) is the righthand-side vector, which we have seen several times before. But now these take on a new significance. Notice that if we take the first row of \\(A\\) and multiply it by \\(\\mathbf{x}\\) we get the left-hand side of the first equation of our system. Likewise for the second and third rows. Therefore, we may write in the language of matrices that\n\n\n\n\\[\nA \\mathbf{x}=\\left[\\begin{array}{lll}\n1 & 1 & 1 \\\\\n2 & 2 & 5 \\\\\n4 & 6 & 8\n\\end{array}\\right]\\left[\\begin{array}{l}\nx_{1} \\\\\nx_{2} \\\\\nx_{3}\n\\end{array}\\right]=\\left[\\begin{array}{r}\n4 \\\\\n11 \\\\\n24\n\\end{array}\\right]=\\mathbf{b}\n\\]\n\nWe can multiply this out and get that \\(x_1\\) multiplies each of the elements in the first column… (show this)"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#matrix-multiplication-as-a-linear-combination-of-column-vectors",
    "href": "lectures/ch2_lecture1.html#matrix-multiplication-as-a-linear-combination-of-column-vectors",
    "title": "Ch2 Lecture 1",
    "section": "Matrix Multiplication as a Linear Combination of Column Vectors",
    "text": "Matrix Multiplication as a Linear Combination of Column Vectors\nAnother way of writing this system:\n\\[\nx_{1}\\left[\\begin{array}{l}\n1 \\\\\n2 \\\\\n4\n\\end{array}\\right]+x_{2}\\left[\\begin{array}{l}\n1 \\\\\n2 \\\\\n6\n\\end{array}\\right]+x_{3}\\left[\\begin{array}{l}\n1 \\\\\n5 \\\\\n8\n\\end{array}\\right]=\\left[\\begin{array}{r}\n4 \\\\\n11 \\\\\n24\n\\end{array}\\right] .\n\\]\n\nName the columns of A as \\(\\mathbf{a_1}, \\mathbf{a_2}, \\mathbf{a_3}\\), then we can write the matrix as \\(A=\\left[\\mathbf{a}_{1}, \\mathbf{a}_{2}, \\mathbf{a}_{3}\\right]\\)\n\n\nLet \\(\\mathbf{x}=\\left(x_{1}, x_{2}, x_{3}\\right)\\). Then\n\\[\nA \\mathbf{x}=x_{1} \\mathbf{a}_{1}+x_{2} \\mathbf{a}_{2}+x_{3} \\mathbf{a}_{3} .\n\\]\nThis is a very important way of thinking about matrix multiplication\n\nWhat happens if we are trying to get something which can’t be made up of any combination of the columns of \\(A\\)?\nWhat happens if two or more of the columns of \\(A\\) are the same?\nWhat if they are multiples of one another?\nWhat if one column is a linear combination of several others?"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#try-it-yourself",
    "href": "lectures/ch2_lecture1.html#try-it-yourself",
    "title": "Ch2 Lecture 1",
    "section": "Try it yourself",
    "text": "Try it yourself\nTry to find the solution for the following system, by trying different values of \\(x_i\\) to use in a sum of the columns of \\(A\\).\n\\[ A \\mathbf{x} = \\left[\\begin{array}{lll}   1 & 1 & 1 \\\\   2 & 2 & 5 \\\\   4 & 6 & 8 \\end{array}\\right]\\left[\\begin{array}{l} x_1 \\\\ x_2 \\\\ x_3 \\end{array}\\right]=x_{1} \\mathbf{a}_{1}+x_{2} \\mathbf{a}_{2}+x_{3} \\mathbf{a}_{3} =\\left[\\begin{array}{l} 6 \\\\ 21 \\\\ 38 \\end{array}\\right]\n\\]\n\nThe answer is 2,1,3\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nNow try changing the right-hand side to a different vector. Can you still find a solution? (You may need to use non-integer values for the \\(x\\)’s.)"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#section-3",
    "href": "lectures/ch2_lecture1.html#section-3",
    "title": "Ch2 Lecture 1",
    "section": "",
    "text": "This is a slightly changed system.\n\\[ A \\mathbf{x} = \\left[\\begin{array}{lll}   1 & 1 & 2 \\\\   1 & 2 & 2 \\\\   4 & 6 & 8 \\end{array}\\right]\\left[\\begin{array}{l} x_1 \\\\ x_2 \\\\ x_3 \\end{array}\\right]=x_{1} \\mathbf{a}_{1}+x_{2} \\mathbf{a}_{2}+x_{3} \\mathbf{a}_{3} =\\left[\\begin{array}{l} 11 \\\\ 12 \\\\ 46 \\end{array}\\right]\n\\]\n\nThe answer is 2, 1, 4\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nAre you able to find more than one solution? Can you find a right-hand-side that doesn’t have a solution?"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#example-benzoic-acid",
    "href": "lectures/ch2_lecture1.html#example-benzoic-acid",
    "title": "Ch2 Lecture 1",
    "section": "Example: Benzoic acid",
    "text": "Example: Benzoic acid\nBenzoic acid (chemical formula \\(\\mathrm{C}_{7} \\mathrm{H}_{6} \\mathrm{O}_{2}\\) ) oxidizes to carbon dioxide and water.\n\\[\n\\mathrm{C}_{7} \\mathrm{H}_{6} \\mathrm{O}_{2}+\\mathrm{O}_{2} \\rightarrow \\mathrm{CO}_{2}+\\mathrm{H}_{2} \\mathrm{O} .\n\\]\nBalance this equation. (Make the number of atoms of each element match on the two sides of the equation.)\n\nDefine \\((c, o, h)\\) as the number of atoms of carbon, oxygen, and hydrogen atoms in the equation.\n\n\nNext let \\(x_1\\), \\(x_2\\), \\(x_3\\), and \\(x_4\\) be the number of molecules of benzoic acid, oxygen, carbon dioxide, and water, respectively.\n\n\nThen we have the equation\n\\[\nx_{1}\\left[\\begin{array}{l}\n7 \\\\\n2 \\\\\n6\n\\end{array}\\right]+x_{2}\\left[\\begin{array}{l}\n0 \\\\\n2 \\\\\n0\n\\end{array}\\right]=x_{3}\\left[\\begin{array}{l}\n1 \\\\\n2 \\\\\n0\n\\end{array}\\right]+x_{4}\\left[\\begin{array}{l}\n0 \\\\\n1 \\\\\n2\n\\end{array}\\right] .\n\\]"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#section-4",
    "href": "lectures/ch2_lecture1.html#section-4",
    "title": "Ch2 Lecture 1",
    "section": "",
    "text": "Rearrange:\n\\[\nx_{1}\\left[\\begin{array}{l}\n7 \\\\\n2 \\\\\n6\n\\end{array}\\right]+x_{2}\\left[\\begin{array}{l}\n0 \\\\\n2 \\\\\n0\n\\end{array}\\right]=x_{3}\\left[\\begin{array}{l}\n1 \\\\\n2 \\\\\n0\n\\end{array}\\right]+x_{4}\\left[\\begin{array}{l}\n0 \\\\\n1 \\\\\n2\n\\end{array}\\right] .\n\\]\nbecomes\n\\[\nA \\mathbf{x}=\\left[\\begin{array}{cccc}\n7 & 0 & -1 & 0 \\\\\n2 & 2 & -2 & -1 \\\\\n6 & 0 & 0 & -2\n\\end{array}\\right]\\left[\\begin{array}{l}\nx_{1} \\\\\nx_{2} \\\\\nx_{3} \\\\\nx_{4}\n\\end{array}\\right]=\\left[\\begin{array}{l}\n0 \\\\\n0 \\\\\n0\n\\end{array}\\right]\n\\]\n\nThis is just like a matrix like we were solving in class last time."
  },
  {
    "objectID": "lectures/ch2_lecture1.html#section-5",
    "href": "lectures/ch2_lecture1.html#section-5",
    "title": "Ch2 Lecture 1",
    "section": "",
    "text": "We solve with row reduction:\n\\[\n\\begin{aligned}\n& {\\left[\\begin{array}{cccc}\n7 & 0 & -1 & 0 \\\\\n2 & 2 & -2 & -1 \\\\\n6 & 0 & 0 & -2\n\\end{array}\\right] \\xrightarrow[E_{21}\\left(-\\frac{2}{7}\\right)]{E_{31}\\left(-\\frac{6}{7}\\right)}\\left[\\begin{array}{cccc}\n7 & 0 & -1 & 0 \\\\\n0 & 2 & -\\frac{12}{7} & -1 \\\\\n0 & 0 & \\frac{6}{7} & -2\n\\end{array}\\right] \\begin{array}{c}\nE_{1}\\left(\\frac{1}{7}\\right) \\\\\nE_{2}\\left(\\frac{1}{2}\\right) \\\\\nE_{3}\\left(\\frac{7}{6}\\right)\n\\end{array} \\left[\\begin{array}{cccc}\n1 & 0 & -\\frac{1}{7} & 0 \\\\\n0 & 1 & -\\frac{6}{7} & -\\frac{1}{2} \\\\\n0 & 0 & 1 & -\\frac{7}{3}\n\\end{array}\\right]} \\\\\n& \\begin{array}{l}\n\\overrightarrow{E_{23}\\left(\\frac{6}{7}\\right)} \\\\\nE_{13}\\left(\\frac{1}{7}\\right)\n\\end{array}\\left[\\begin{array}{llll}\n1 & 0 & 0 & -\\frac{1}{3} \\\\\n0 & 1 & 0 & -\\frac{5}{2} \\\\\n0 & 0 & 1 & -\\frac{7}{3}\n\\end{array}\\right]\n\\end{aligned}\n\\]\n\n\\(x_{4}\\) is free, others are bound. Now pick smallest \\(x_4\\) where others are all positive integers…\n\n\n\\[\n2 \\mathrm{C}_{7} \\mathrm{H}_{6} \\mathrm{O}_{2}+15 \\mathrm{O}_{2} \\rightarrow 14 \\mathrm{CO}_{2}+2 \\mathrm{H}_{2} \\mathrm{O}\n\\]"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#scaling",
    "href": "lectures/ch2_lecture1.html#scaling",
    "title": "Ch2 Lecture 1",
    "section": "Scaling",
    "text": "Scaling\nGoal: Make a matrix that will take a vector of coordinates \\(\\mathbf{x}\\) and scale each coordinate \\(x_i\\) by a factor of \\(z_i\\).\n\\[ A x = \\left[\\begin{array}{ll} a1 & a2 \\\\ a3 & a4 \\end{array}\\right] \\left[\\begin{array}{l} x_1 \\\\ x_2 \\end{array}\\right] = \\left[\\begin{array}{l} z_1 \\times x_1 \\\\ z_2\\times  x_2 \\end{array}\\right] \\]\n\n\\[ A = \\left[\\begin{array}{ll} z_1 & 0 \\\\ 0 & z_2 \\end{array}\\right] \\]"
  },
  {
    "objectID": "notebooks/pagerank_tutorial.html",
    "href": "notebooks/pagerank_tutorial.html",
    "title": "PageRank Tutorial",
    "section": "",
    "text": "import sympy as sym\n\nWe make a matrix using the sym.Matrix function.\n\nT = sym.Matrix([[1,2,3],[2,1,3],[2,1,1]])\nT\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 2 & 3\\\\2 & 1 & 3\\\\2 & 1 & 1\\end{matrix}\\right]\\)\n\n\nWe can create symbolic variables, and put them into the matrix if we want…\n\nx1=sym.var('x1'); x2=sym.var('x2');x3=sym.var('x3');x4=sym.var('x4')\n\n\nx1\n\n\\(\\displaystyle x_{1}\\)\n\n\n\nT2 = sym.Matrix([[1,x2,3],[2,1,3],[2,x1,1]])\nT2\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & x_{2} & 3\\\\2 & 1 & 3\\\\2 & x_{1} & 1\\end{matrix}\\right]\\)\n\n\nIf we input fractions, they are by default converted to floating point numbers:\n\nT3 = sym.Matrix([[1,x2,1/3],[2,1,3],[2,x1,1]])\nT3\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & x_{2} & 0.333333333333333\\\\2 & 1 & 3\\\\2 & x_{1} & 1\\end{matrix}\\right]\\)\n\n\nIt’s nicer to input fractions and keep them as fractions:\n\nT4 = sym.Matrix([[1,x2,sym.Rational(1,3)],[2,1,3],[2,x1,1]])\nT4\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & x_{2} & \\frac{1}{3}\\\\2 & 1 & 3\\\\2 & x_{1} & 1\\end{matrix}\\right]\\)\n\n\nWe can substitute values in for variables:\n\nT4.subs(x1,5)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & x_{2} & \\frac{1}{3}\\\\2 & 1 & 3\\\\2 & 5 & 1\\end{matrix}\\right]\\)\n\n\nWe can find reduced row echelon form:\n\nT4.rref()\n\n(Matrix([\n [1, 0, 0],\n [0, 1, 0],\n [0, 0, 1]]),\n (0, 1, 2))\n\n\nThis outputs the RREFand tells us which columns correspond to bound variables.\nLastly, we can do Gauss-Jordan elimination to solve a system of equations with a matrix and a right-hand-side:\n\nT4.gauss_jordan_solve(sym.Matrix([2,1,3]))\n\n(Matrix([\n [(17*x1 - 24*x2 - 3)/(7*x1 - 12*x2 - 1)],\n [                 -4/(7*x1 - 12*x2 - 1)],\n [(-9*x1 + 12*x2 + 3)/(7*x1 - 12*x2 - 1)]]),\n Matrix(0, 1, []))\n\n\nThat’s messy! It’s exporting several things, but the one we want is the first.\n\nT4.gauss_jordan_solve(sym.Matrix([2,1,3]))[0]\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{17 x_{1} - 24 x_{2} - 3}{7 x_{1} - 12 x_{2} - 1}\\\\- \\frac{4}{7 x_{1} - 12 x_{2} - 1}\\\\\\frac{- 9 x_{1} + 12 x_{2} + 3}{7 x_{1} - 12 x_{2} - 1}\\end{matrix}\\right]\\)"
  },
  {
    "objectID": "notebooks/pagerank_tutorial.html#set-up-the-environment.-import-the-sympy-library.",
    "href": "notebooks/pagerank_tutorial.html#set-up-the-environment.-import-the-sympy-library.",
    "title": "PageRank Tutorial",
    "section": "",
    "text": "import sympy as sym\n\nWe make a matrix using the sym.Matrix function.\n\nT = sym.Matrix([[1,2,3],[2,1,3],[2,1,1]])\nT\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 2 & 3\\\\2 & 1 & 3\\\\2 & 1 & 1\\end{matrix}\\right]\\)\n\n\nWe can create symbolic variables, and put them into the matrix if we want…\n\nx1=sym.var('x1'); x2=sym.var('x2');x3=sym.var('x3');x4=sym.var('x4')\n\n\nx1\n\n\\(\\displaystyle x_{1}\\)\n\n\n\nT2 = sym.Matrix([[1,x2,3],[2,1,3],[2,x1,1]])\nT2\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & x_{2} & 3\\\\2 & 1 & 3\\\\2 & x_{1} & 1\\end{matrix}\\right]\\)\n\n\nIf we input fractions, they are by default converted to floating point numbers:\n\nT3 = sym.Matrix([[1,x2,1/3],[2,1,3],[2,x1,1]])\nT3\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & x_{2} & 0.333333333333333\\\\2 & 1 & 3\\\\2 & x_{1} & 1\\end{matrix}\\right]\\)\n\n\nIt’s nicer to input fractions and keep them as fractions:\n\nT4 = sym.Matrix([[1,x2,sym.Rational(1,3)],[2,1,3],[2,x1,1]])\nT4\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & x_{2} & \\frac{1}{3}\\\\2 & 1 & 3\\\\2 & x_{1} & 1\\end{matrix}\\right]\\)\n\n\nWe can substitute values in for variables:\n\nT4.subs(x1,5)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & x_{2} & \\frac{1}{3}\\\\2 & 1 & 3\\\\2 & 5 & 1\\end{matrix}\\right]\\)\n\n\nWe can find reduced row echelon form:\n\nT4.rref()\n\n(Matrix([\n [1, 0, 0],\n [0, 1, 0],\n [0, 0, 1]]),\n (0, 1, 2))\n\n\nThis outputs the RREFand tells us which columns correspond to bound variables.\nLastly, we can do Gauss-Jordan elimination to solve a system of equations with a matrix and a right-hand-side:\n\nT4.gauss_jordan_solve(sym.Matrix([2,1,3]))\n\n(Matrix([\n [(17*x1 - 24*x2 - 3)/(7*x1 - 12*x2 - 1)],\n [                 -4/(7*x1 - 12*x2 - 1)],\n [(-9*x1 + 12*x2 + 3)/(7*x1 - 12*x2 - 1)]]),\n Matrix(0, 1, []))\n\n\nThat’s messy! It’s exporting several things, but the one we want is the first.\n\nT4.gauss_jordan_solve(sym.Matrix([2,1,3]))[0]\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{17 x_{1} - 24 x_{2} - 3}{7 x_{1} - 12 x_{2} - 1}\\\\- \\frac{4}{7 x_{1} - 12 x_{2} - 1}\\\\\\frac{- 9 x_{1} + 12 x_{2} + 3}{7 x_{1} - 12 x_{2} - 1}\\end{matrix}\\right]\\)"
  },
  {
    "objectID": "notebooks/pagerank_tutorial.html#now-you-try",
    "href": "notebooks/pagerank_tutorial.html#now-you-try",
    "title": "PageRank Tutorial",
    "section": "Now you try!",
    "text": "Now you try!\nCreate a matrix representing the system of equations for the “third try” in the PageRank problem:\n\\[\n\\begin{aligned}\n& x_{1}=\\frac{x_{2}}{1}+\\frac{x_{3}}{3} \\\\\n& x_{2}=\\frac{x_{1}}{2}+\\frac{x_{3}}{3} \\\\\n& x_{3}=\\frac{x_{1}}{2}+\\frac{x_{4}}{1} \\\\\n& x_{4}=\\frac{x_{3}}{3} .\n\\end{aligned}\n\\]\nNow find the RREF form of this matrix. What does that tell you about the system?\nNext, use the gauss_jordan_solve. What’s surprising (or not) about these results?\nSubstitute a specific value to get a particular solution…"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#shearing",
    "href": "lectures/ch2_lecture1.html#shearing",
    "title": "Ch2 Lecture 1",
    "section": "Shearing",
    "text": "Shearing\nShearing: adding a constant shear factor times one coordinate to another coordinate of the point.\nGoal: make a matrix which will transform each coordinate \\(x_i\\) into \\(x_i + \\sum_{j \\ne i} s_{j} \\times x_j\\).\n\\[ A x = \\left[\\begin{array}{ll} a1 & a2 \\\\ a3 & a4 \\end{array}\\right] \\left[\\begin{array}{l} x_1 \\\\ x_2 \\end{array}\\right] = \\left[\\begin{array}{l} x_1 + s_2 x_2 \\\\ x_2 + s_1 x_1 \\end{array}\\right] \\]\n\n\\[ A = \\left[\\begin{array}{ll} 1 & s_2 \\\\ s_1 & 1 \\end{array}\\right] \\]"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#example",
    "href": "lectures/ch2_lecture1.html#example",
    "title": "Ch2 Lecture 1",
    "section": "Example",
    "text": "Example\n\nLet the scaling operator \\(S\\) on points in two dimensions have scale factors of \\(\\frac{3}{2}\\) in the \\(x\\)-direction and \\(\\frac{1}{2}\\) in the \\(y\\)-direction.\nLet the shearing operator \\(H\\) on these points have a shear factor of \\(\\frac{1}{2}\\) by the \\(y\\)-coordinate on the \\(x\\)-coordinate.\nExpress these operators as matrix operators and graph their action on four unit squares situated diagonally from the origin."
  },
  {
    "objectID": "lectures/ch2_lecture1.html#solution",
    "href": "lectures/ch2_lecture1.html#solution",
    "title": "Ch2 Lecture 1",
    "section": "Solution",
    "text": "Solution\n\nScaling operator \\(S\\):\n\n\n\\[\nS((x, y))=\\left[\\begin{array}{c}\n\\frac{3}{2} x \\\\\n\\frac{1}{2} y\n\\end{array}\\right]=\\left[\\begin{array}{cc}\n\\frac{3}{2} & 0 \\\\\n0 & \\frac{1}{2}\n\\end{array}\\right]\\left[\\begin{array}{l}\nx \\\\\ny\n\\end{array}\\right]=T_{A}((x, y))\n\\]"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#verify",
    "href": "lectures/ch2_lecture1.html#verify",
    "title": "Ch2 Lecture 1",
    "section": "Verify:",
    "text": "Verify:\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/ch2_lecture1.html#section-6",
    "href": "lectures/ch2_lecture1.html#section-6",
    "title": "Ch2 Lecture 1",
    "section": "",
    "text": "Shearing operator \\(H\\):\n\n\\[\nH((x, y))=\\left[\\begin{array}{c}\nx+\\frac{1}{2} y \\\\\ny\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n1 & \\frac{1}{2} \\\\\n0 & 1\n\\end{array}\\right]\\left[\\begin{array}{l}\nx \\\\\ny\n\\end{array}\\right]=T_{B}((x, y))\n\\]"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#verify-1",
    "href": "lectures/ch2_lecture1.html#verify-1",
    "title": "Ch2 Lecture 1",
    "section": "Verify",
    "text": "Verify\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/ch2_lecture1.html#concatenation-of-operators-s-and-h",
    "href": "lectures/ch2_lecture1.html#concatenation-of-operators-s-and-h",
    "title": "Ch2 Lecture 1",
    "section": "Concatenation of operators \\(S\\) and \\(H\\)",
    "text": "Concatenation of operators \\(S\\) and \\(H\\)\n\nThe concatenation \\(S \\circ H\\) of the scaling operator \\(S\\) and shearing operator \\(H\\) is the action of scaling followed by shearing.\nFunction composition corresponds to matrix multiplication\n\n\n\\[\n\\begin{aligned}\nS \\circ H((x, y)) & =T_{A} \\circ T_{B}((x, y))=T_{A B}((x, y)) \\\\\n& =\\left[\\begin{array}{cc}\n\\frac{3}{2} & 0 \\\\\n0 & \\frac{1}{2}\n\\end{array}\\right]\\left[\\begin{array}{ll}\n1 & \\frac{1}{2} \\\\\n0 & 1\n\\end{array}\\right]\\left[\\begin{array}{l}\nx \\\\\ny\n\\end{array}\\right]=\\left[\\begin{array}{cc}\n\\frac{3}{2} & \\frac{3}{4} \\\\\n0 & \\frac{1}{2}\n\\end{array}\\right]\\left[\\begin{array}{l}\nx \\\\\ny\n\\end{array}\\right]=T_{C}((x, y)),\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#verify-2",
    "href": "lectures/ch2_lecture1.html#verify-2",
    "title": "Ch2 Lecture 1",
    "section": "Verify",
    "text": "Verify\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/ch2_lecture1.html#rotation",
    "href": "lectures/ch2_lecture1.html#rotation",
    "title": "Ch2 Lecture 1",
    "section": "Rotation",
    "text": "Rotation\nGoal: rotate a point in two dimensions counterclockwise by an angle \\(\\phi\\). Suppose the point is initally at an angle \\(\\theta\\) from the \\(x\\)-axis."
  },
  {
    "objectID": "lectures/ch2_lecture1.html#section-7",
    "href": "lectures/ch2_lecture1.html#section-7",
    "title": "Ch2 Lecture 1",
    "section": "",
    "text": "\\[\n\\left[\\begin{array}{l}\nx \\\\\ny\n\\end{array}\\right]\n=\\left[\\begin{array}{l}\nr \\cos \\theta \\\\\nr \\sin \\theta\n\\end{array}\\right]\n\\]\nWe can use trigonometry to find the values of x and y after rotation.\n\\[\n\\left[\\begin{array}{l}\nx^{\\prime} \\\\\ny^{\\prime}\n\\end{array}\\right] =\\left[\\begin{array}{l}\nr \\cos (\\theta+\\phi) \\\\\nr \\sin (\\theta+\\phi)\n\\end{array}\\right]=\\left[\\begin{array}{l}\nr \\cos \\theta \\cos \\phi-r \\sin \\theta \\sin \\phi \\\\\nr \\sin \\theta \\cos \\phi+r \\cos \\theta \\sin \\phi\n\\end{array}\\right]\n\\]\n\nUsing the double-angle rule,\n\\[\n=\\left[\\begin{array}{rr}\n\\cos \\theta &-\\sin \\theta \\\\\n\\sin \\theta & \\cos \\theta\n\\end{array}\\right]\\left[\\begin{array}{l}\nr \\cos \\phi \\\\\nr \\sin \\phi\n\\end{array}\\right]=\\left[\\begin{array}{rr}\n\\cos \\theta&-\\sin \\theta \\\\\n\\sin \\theta & \\cos \\theta\n\\end{array}\\right]\\left[\\begin{array}{l}\nx \\\\\ny\n\\end{array}\\right]\n\\]\n\n\nSo we define the rotation matrix \\(R(\\theta)\\) by\n\\[\nR(\\theta)=\\left[\\begin{array}{rr}\n\\cos \\theta & -\\sin \\theta \\\\\n\\sin \\theta & \\cos \\theta\n\\end{array}\\right]\n\\]"
  },
  {
    "objectID": "lectures/ch2_lecture1.html#now-you-try",
    "href": "lectures/ch2_lecture1.html#now-you-try",
    "title": "Ch2 Lecture 1",
    "section": "Now you try",
    "text": "Now you try\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n\ndiffusion.gif\nreaction.gif\n1dRD.gif\n2dRD.png"
  },
  {
    "objectID": "lectures/ch2_lecture2.html#definitions",
    "href": "lectures/ch2_lecture2.html#definitions",
    "title": "Ch2 Lecture 2",
    "section": "Definitions",
    "text": "Definitions\nDefinition: A discrete linear dynamical system is a sequence of vectors \\(\\mathbf{x}^{(k)}, k=0,1, \\ldots\\), called states, which is defined by an initial vector \\(\\mathbf{x}^{(0)}\\) and by the rule\n\\[\n\\mathbf{x}^{(k+1)}=A \\mathbf{x}^{(k)}+\\mathbf{b}_{k}, \\quad k=0,1, \\ldots\n\\]\n\n\n\\(A\\) is a fixed square matrix, called the transition matrix of the system\nvectors \\(\\mathbf{b}_{k}, k=0,1, \\ldots\\) are called the input vectors of the system.\nIf we don’t specify input vectors, assume that \\(\\mathbf{b}_{k}=\\mathbf{0}\\) for all \\(k\\). Then call the system a homogeneous dynamical system."
  },
  {
    "objectID": "lectures/ch2_lecture2.html#stability",
    "href": "lectures/ch2_lecture2.html#stability",
    "title": "Ch2 Lecture 2",
    "section": "Stability",
    "text": "Stability\nAn important question: is the system stable?\nDoes \\(\\mathbf{x}^{(k)}\\) tend towards a constant state \\(\\mathrm{x}\\)?\n\nIf system is homogeneous, then if a stable state is the initial state, it will equal all subsequent states.\nDefinition: A vector \\(\\mathbf{x}\\) satisfying \\(\\mathbf{x}=A \\mathbf{x}\\), for a square matrix \\(A\\), is called a stationary vector for \\(A\\).\n\n\nIf \\(A\\) is the transition matrix for a homogeneous discrete dynamical system, we also call such a vector a stationary state."
  },
  {
    "objectID": "lectures/ch2_lecture2.html#example",
    "href": "lectures/ch2_lecture2.html#example",
    "title": "Ch2 Lecture 2",
    "section": "Example",
    "text": "Example\n\nTwo toothpaste companies compete for customers in a fixed market\nEach customer uses either Brand A or Brand B.\nBuying habits. In each quarter:\n\n\\(30 \\%\\) of A users will switch to B, while the rest stay with A.\n\\(40 \\%\\) of B users will switch to A , while the the rest stay with B.\n\nThis is an example of a Markov chain model."
  },
  {
    "objectID": "lectures/ch2_lecture2.html#section",
    "href": "lectures/ch2_lecture2.html#section",
    "title": "Ch2 Lecture 2",
    "section": "",
    "text": "Let \\(a_1\\) be the fraction of customers using Brand A at the end of the first quarter, and \\(b_1\\) be the fraction using Brand B.\nThen we have the following system of equations: \\[\n\\begin{aligned}\na_{1} & =0.7 a_{0}+0.4 b_{0} \\\\\nb_{1} & =0.3 a_{0}+0.6 b_{0}\n\\end{aligned}\n\\]\n\nMore generally,\n\\[\n\\begin{aligned}\na_{k+1} & =0.7 a_{k}+0.4 b_{k} \\\\\nb_{k+1} & =0.3 a_{k}+0.6 b_{k} .\n\\end{aligned}\n\\]\n\n\nIn matrix form,\n\\[\n\\mathbf{x}^{(k)}=\\left[\\begin{array}{c}\na_{k} \\\\\nb_{k}\n\\end{array}\\right] \\text { and } A=\\left[\\begin{array}{ll}\n0.7 & 0.4 \\\\\n0.3 & 0.6\n\\end{array}\\right]\n\\]\nwith\n\\[\n\\mathbf{x}^{(k+1)}=A \\mathbf{x}^{(k)}\n\\]"
  },
  {
    "objectID": "lectures/ch2_lecture2.html#section-1",
    "href": "lectures/ch2_lecture2.html#section-1",
    "title": "Ch2 Lecture 2",
    "section": "",
    "text": "We can continue into future quarters by multiplying by \\(A\\) again: \\[\n\\mathbf{x}^{(2)}=A \\mathbf{x}^{(1)}=A \\cdot\\left(A \\mathbf{x}^{(0)}\\right)=A^{2} \\mathbf{x}^{(0)}\n\\]\n\nIn general,\n\\[\n\\mathbf{x}^{(k)}=A \\mathbf{x}^{(k-1)}=A^{2} \\mathbf{x}^{(k-2)}=\\cdots=A^{k} \\mathbf{x}^{(0)} .\n\\]\n\n\nThis is true of any homogeneous linear dynamical system!\nFor any positive integer \\(k\\) and discrete dynamical system with transition matrix \\(A\\) and initial state \\(\\mathbf{x}^{(0)}\\), the \\(k\\)-th state is given by\n\\[\n\\mathbf{x}^{(k)}=A^{k} \\mathbf{x}^{(0)}\n\\]"
  },
  {
    "objectID": "lectures/ch2_lecture2.html#distribution-vector-and-stochastic-matrix",
    "href": "lectures/ch2_lecture2.html#distribution-vector-and-stochastic-matrix",
    "title": "Ch2 Lecture 2",
    "section": "Distribution vector and stochastic matrix",
    "text": "Distribution vector and stochastic matrix\n\n\\(\\mathbf{x}^{(k)}\\) of the toothpaste example are column vectors with nonnegative coordinates that sum to 1.\nSuch vectors are called distribution vectors.\nAlso, each of the columns the matrix \\(A\\) is a distribution vector.\nA square matrix \\(A\\) whose columns are distribution vectors is called a stochastic matrix."
  },
  {
    "objectID": "lectures/ch2_lecture2.html#markov-chain-definition",
    "href": "lectures/ch2_lecture2.html#markov-chain-definition",
    "title": "Ch2 Lecture 2",
    "section": "Markov Chain definition",
    "text": "Markov Chain definition\nA Markov chain is a discrete dynamical system whose initial state \\(\\mathbf{x}^{(0)}\\) is a distribution vector and whose transition matrix \\(A\\) is stochastic, i.e., each column of \\(A\\) is a distribution vector."
  }
]