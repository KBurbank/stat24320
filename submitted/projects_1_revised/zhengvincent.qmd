---
title: "Project 1"
author: "Vincent"
date: "4/14/2024"
latex-auto-mk: true
output: pdf_document
publish: true
css: comments.css
format:
  html:
    code-fold: show
    code-tools: 
      source: true
      toggle: true
---

::: comments
The gas in the tube is excellent now -- I love that you included an animation. I'm still a little curious about why you were getting negative numbers.

 I assume that what the `nsimplify` with the tolerance was doing, in your case, was to set to zero any values that were less than your threshold of 0.01, and any negative numbers you were getting were small enough to be rounded down to zero?

 Of course you are right that negative numbers don't make physical sense. If you were modelling this system in a different context, you might want to try making either your timesteps or your spatial discritization smaller to see if you can get a more accurate result without having to round down to zero; if that didn't work, you might have some issue with the code or with the model itself that you would need to address. However, in this assignment, you don't really have the freedom to change the discretization or the timestep, since you are trying to match the given values. So, I think you did the best you could in this case.

 The sports ranking section is now well explained, thanks.

 Final grades: E E M.
 :::



```{python}
#| echo: false

import sympy as sp
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import PillowWriter
import pandas as pd
import networkx as nx

```

# Markov Chains

## Introduction

Here is the system of equations that represents the scenario.

![Systems of equations](systemofequations.jpeg){width="50%"}

Here is the transition matrix. The market shares after 3 years are shown below given that the initial market shares are equal, which meant that the initial vector is \[1/3, 1/3, 1/3\].

```{python}
#| echo: false
# transition matrix
A = sp.Matrix([[0.5, 0.2, 0.3], [0.2, 0.6, 0.1], [0.3, 0.2, 0.6]])
display(A)
# intial vector
x1, x2, x3 = sp.symbols('x1 x2 x3')
x = sp.Matrix([x1, x2, x3])

# 3 steps, equal shares
xtest = x.subs({x1: 1/3, x2: 1/3, x3: 1/3})
A3 = (A**3)*xtest
display(A3)
```

## Recommendation

As seen in the below graphs, the effect of launching campaign 2 is better than campaign 1. Note that campaign 0 shows what would happen if no campiagn is launched. In that scenario, company C would have the highest market share whereas we would be stuck in the middle. Launching campaign 1 would not change this situation but we would be closer to C. However, launching campaign 2 would allow us to surpass C and have the highest market share, bringing us to 0.4.

```{python}
#| echo: false

# first campaign will convince 20% of the B customers who would otherwise stay with B
# in a given year to switch to A
event1 = 0.6*0.2
B = sp.Matrix([[0.5, 0.2 + event1 , 0.3], [0.2, 0.6 - event1, 0.1], [0.3, 0.2, 0.6]])

#  second advertising campaign would convince 20% 
#  of the customers who would otherwise stay with C in a given year to switch to A
event2 = 0.6*0.2
C = sp.Matrix([[0.5, 0.2 , 0.3 + event2 ], [0.2, 0.6, 0.1], [0.3, 0.2, 0.6 - event2]])

# plotting

steps = np.arange(0, 10, 1)
campaigns = [A, B, C]

xtest1 = x.subs({x1: 1/3, x2: 1/3, x3: 1/3})
xtest2 = x.subs({x1: 0, x2: 1, x3: 0})
xtest3 = x.subs({x1: 0, x2: 0, x3: 1})
xtestlist = [xtest1]

for campaign in campaigns:
    plt.figure()
    plt.title("Campaign" + " " + str(campaigns.index(campaign)))
    for xtest in xtestlist:
        lst = []
        for i in steps:
            l = [i]
            xstep = (campaign**i)*xtest
            l.extend(xstep)
            lst.append(l)
        df = pd.DataFrame(lst, columns=['Step', 'A', 'B', 'C'])
        plt.plot(df['Step'], df['A'], "o-", label='A')
        plt.plot(df['Step'], df['B'], "o-", label='B')
        plt.plot(df['Step'], df['C'], "o-", label='C')
        plt.xlabel('Step')
        plt.ylabel('Porportion of Customers')
        plt.legend()

```

You might have noticed that we're assuming that the market shares are equal at the beginning. However, the transition matrix is a stable discrete dynamical system which would have the same equilibrium state regardless of the initial vector. To identify a stable system, we need the dominant eigenvalue to be equal to 1 which is the case here. An example is seen below where the initial market shares are \[0, 0, 1\].

```{python}
#| echo: false

A.eigenvals()

```

```{python}
#| echo: false

# %%
# plotting

steps = np.arange(0, 10, 1)
campaigns = [A, B, C]

xtest1 = x.subs({x1: 1/3, x2: 1/3, x3: 1/3})
xtest2 = x.subs({x1: 0, x2: 1, x3: 0})
xtest3 = x.subs({x1: 0, x2: 0, x3: 1})
xtestlist = [xtest3]

for campaign in campaigns:
    plt.figure()
    plt.title("Campaign" + " " + str(campaigns.index(campaign)))
    for xtest in xtestlist:
        lst = []
        for i in steps:
            l = [i]
            xstep = (campaign**i)*xtest
            l.extend(xstep)
            lst.append(l)
        df = pd.DataFrame(lst, columns=['Step', 'A', 'B', 'C'])
        plt.plot(df['Step'], df['A'], "o-", label='A')
        plt.plot(df['Step'], df['B'], "o-", label='B')
        plt.plot(df['Step'], df['C'], "o-", label='C')
        plt.xlabel('Step')
        plt.ylabel('Porportion of Customers')
        plt.legend()

```

Further analysis shows that there is a diminishing marginal return if more money is spent on a campaign to take more customers away from B or C. The is shown as the curves are concave down. Additionally, these graphs also show that spending money on taking C's customers is more valuable than taking B's because A increases around 0.15 for the former and 0.1 for the latter. Taking C's customers also makes A the market leader by a significant margin. It should be noted that this also assumes the amount of money it takes to take B's customers is the same as taking C's customers.

Additionally, although the initial market share doesn't matter, it is important to note that we're assuming these events are independent of each other. For example, perhaps customers are more likely to follow the pack if a majority of the population are using companies which means that the market would be more volatile than my simulations suggest. This would also mean that it's more important for us to have the highest market share at the beginning, making initial market shares more important.

# Gas in a Tube

The time dependent reaction diffusion equation is shown below and I translated it to matrix form.

![Equation](reactiondiffusionequation.png){width="50%"}

![Matrix Form](reactiondiffusionmatrix.jpeg){width="50%"}

Note that because there is no continous source of gas, the *kf* is 0.

After this, we can factor the *y* vector at time *t* out (by multiplying the lone *y* vector by the identity matrix). This gives us a way to walk forward to the densities at time *t+1* from the densities at time *t*. To go backwards, we can take the inverse on both sides.

This allows us to estimate the value of D, the diffusion constant by walking backwards from the given densities at t = 270 to try to match the given densities at t = 240. I got a value of D = 0.00004.

From there, we can continue going backwards to t = 0, giving us an initial concentration of â€‹0, 0.0149, 1.01, 6.36, 1.01, 0.0149,0 at each node.

Then, we can go forwards to t = 210 and t = 310 by using the previous equation get the concentrations at those times.


```{python}
#| echo: false

# constants and initial conditions
N = 7 # number of nodes
hsquared = (1/6)**2 # distance between nodes
k = 1 # time step
D = 0.00004

given1 = [0, 0.032, 1.23, 3.69, 1.23, 0.032, 0]
given2 = [0, 0.051, 1.21, 3.48, 1.21, 0.051, 0]

# matrix M
M = sp.zeros(N)
for i in range(N):
    if (i>0):
        M[i-1,i] = 1
    M[i,i] = -2
    if (i<N-1):
      M[i+1,i] = 1
    
# moving from t270 to t240
t = 270
t240 = sp.Matrix(given1)
t270 = sp.Matrix(given2)
current = t270

A = sp.eye(N) + (D*k/(hsquared))*M

Ainv= A.inv()

while t > 240:
    current = sp.nsimplify((Ainv)*current, tolerance=0.01,rational=True)
    t -= 1

display("t = 240", current.evalf(3))

# moving from t240 to t0
while t > 0:
    current = sp.nsimplify((Ainv)*current, tolerance=0.015,rational=True)
    t -= 1

display("t = 0", current.evalf(3))
initial = current

# moving from t0 to t210
while t < 210:
    current = A*current
    t += 1

display("t = 210", current.evalf(3))

while t < 310:
    current = A*current
    t += 1

display("t = 310", current.evalf(3))

```

I've also included an animation of the gas concentrations from the initial state to t = 310. One can see how the points I calculated comes close the points given. A solution that allows negative values would come closer to the given values but here, I've coverted decimals to fractions with a tolerance of 0.01.

```{python}
#| echo: false

fig = plt.figure()
l, = plt.plot([],[], 'k-')

meter = np.arange(0, 7, 1)/6
meter

plt.plot(meter, given1, label='Given t = 240')
plt.plot(meter, given2, label='Given t = 270')
plt.legend()
plt.xlabel('Meter')
plt.ylabel('Concentration')

plt.xlim(0, 1)
plt.ylim(0, 8)


def func(x):
    return (A)*x

writer = PillowWriter(fps=20, metadata=dict(title='Movie', artist = "me"))

current = initial

with writer.saving(fig, "gas.gif",100):
    for i in np.linspace(0,310,311):
        xval = meter
        yval = func(current)
        current = yval

        l.set_data(xval, yval)

        writer.grab_frame()

```

![Diffusion Over Time](gas.gif)


# Sports Ranking

## Win Loss Ratio

When first ranking the teams based on win loss ratio, we see that team 7 is the best team with a ratio of 5 and Team 4 is the worst team with a ratio of 0.2. This is done by summing the *i*th row to get the number of wins and the *i*th column to get the number of losses and then dividing to get the win loss ratio of the *i*th team.

```{python}
#| echo: false

#adjacency matrix
M = np.zeros((7,7))
M[0,1] = 1
M[6,2] = 1
M[1,3] = 1
M[3,4] = 1
M[2,1] = 1
M[4,0] = 1
M[5,0] = 1
M[2,0] = 1
M[6,1] = 1
M[1,5] = 1
M[2,3] = 1
M[6,3] = 1
M[4,6] = 1
M[5,3] = 1
M[2,4] = 1
M[4,5] = 1
M[6,0] = 1
M[4,1] = 1
M[6,5] = 1
M[0,3] = 1
M[5,2] = 1
display(M)

# win loss
team = np.arange(1,8)
wins = np.sum(M, axis=1)
losses = np.sum(M, axis=0)
df = pd.DataFrame({'Team': team, 'Wins': wins, 'Losses': losses, 'Ratio': wins/losses}).sort_values(by='Ratio', ascending=False).set_index('Team')
display(df)
```


## Vertex Power

To rank the teams based on vertex power, I took the square of the adjacency matrix and added the adjacency matrix to get the vertex power matrix. The square of the matrix takes into account the wins of the team that the team beat, which thus takes into account the strength the opponent. The rankings are similar but this ranking broke ties that were seen in the win loss ranking.

```{python}
# directed graph 
G = nx.DiGraph() 
rows, columns = M.shape
for i in range(rows): 
 for j in range(columns): 
   if M[i][j] == 1: 
      G.add_edge(i+1,j+1) 
nx.draw(G, with_labels=True, node_size = 5000, node_color = 'lightblue', font_size = 20, font_color = 'black')

Msquared = np.dot(M,M)

vertex_power_matrix = Msquared + M
vertex_power = np.sum(vertex_power_matrix, axis=1)
df = pd.DataFrame({'Team': team, 'Vertex Power': vertex_power}).sort_values(by='Vertex Power', ascending=False).set_index('Team')
df
```

## Reverse Page Rank
Note that I used alpha = 0.85 and the teleportation vector is \[1/7, 1/7, 1/7, 1/7, 1/7, 1/7, 1/7\].

This ranking is done by taking the transpose of the matrix and applying the equation (I - aP)x = (1-a)v where P is the transition matrix, v is the teleportation vector, and a is the damping factor. The general intuition behind this method is that it tells us the amount of different teams that one specific team would lead to. Applied to this case, we're ranking by the strength of each team. 

The most notable change is that 5 first rather than 7 and this difference could be due to the teleportation vector. The intuition behind the teleportation vector in this scenario is that we're making it equally likely that a team beats another team, thus reducing the impact of the other wins. Additionally, we can note that 5 did beat 7 which beat a lot of other teams and while this is taken into account in the vertex power ranking, it perhaps is emphasized more here.

```{python}

# reverse graph

M = np.zeros((7,7))
M[0,1] = 1
M[6,2] = 1
M[1,3] = 1
M[3,4] = 1
M[2,1] = 1
M[4,0] = 1
M[5,0] = 1
M[2,0] = 1
M[6,1] = 1
M[1,5] = 1
M[2,3] = 1
M[6,3] = 1
M[4,6] = 1
M[5,3] = 1
M[2,4] = 1
M[4,5] = 1
M[6,0] = 1
M[4,1] = 1
M[6,5] = 1
M[0,3] = 1
M[5,2] = 1

T = M.transpose()
D = np.identity(7)
for i in range(7):
    D[i,i] = 1/(np.sum(T[i],axis = 0))

# transition matrix
P = np.dot(T.transpose(),D)


# teleportation vector
v = np.array([1/7, 1/7, 1/7, 1/7, 1/7, 1/7, 1/7])
a = 0.85

lhs = (np.identity(7) - a * P)
rhs = (1-a) * v

x = np.linalg.solve(lhs, rhs)
df = pd.DataFrame({'Team': team, 'Reverse Page Rank': x}).sort_values(by='Reverse Page Rank', ascending=False).set_index('Team')
df

```

## Weighted Vertex Power

With the added weights to the adjacency matrix, the ranking becomes more accurate. Weights help take into consideration how convincingly the team won while punishing those that were a closer game. Rankings show again, and more convincingly, that 7 is at the top with 5 not too close behind but the rest of the teams are more spread out. This helps show that more nuance in the skill disparity between the teams. 

Note I couldn't figure out how to rename the nodes to 1-7 instead of 0-6.
```{python}
# weighted adjacency matrix
M = np.zeros((7,7))
M[0,1] = 4
M[6,2] = 8
M[1,3] = 7
M[3,4] = 3
M[2,1] = 7
M[4,0] = 7
M[5,0] = 23
M[2,0] = 15
M[6,1] = 6
M[1,5] = 18
M[2,3] = 13
M[6,3] = 14
M[4,6] = 7
M[5,3] = 13
M[2,4] = 7
M[4,5] = 18
M[6,0] = 45
M[4,1] = 10
M[6,5] = 19
M[0,3] = 14
M[5,2] = 13

display(M)

G = nx.from_numpy_array(np.matrix(M), create_using=nx.DiGraph)


layout = nx.spring_layout(G)

nx.draw(G, layout, with_labels=True, node_size = 1000, node_color = 'lightblue', font_size = 20, font_color = 'black')
labels = nx.get_edge_attributes(G, "weight")
nx.draw_networkx_edge_labels(G, pos=layout, edge_labels=labels)
plt.show()

Msquared = np.dot(M,M)

vertex_power_matrix = Msquared + M
vertex_power = np.sum(vertex_power_matrix, axis=1)
df = pd.DataFrame({'Team': team, 'Vertex Power': vertex_power}).sort_values(by='Vertex Power', ascending=False).set_index('Team')
df

```
